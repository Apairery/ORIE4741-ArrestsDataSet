{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "p = matplotlib.rcParams\n",
    "p[\"font.family\"] = \"Times New Roman\" #\"sans-serif\"\n",
    "# p[\"font.sans-serif\"] = [\"SimHei\", \"Tahoma\"]\n",
    "p[\"font.size\"] = 20\n",
    "p[\"axes.unicode_minus\"] = False\n",
    "p['lines.linewidth'] = 2\n",
    "p['pdf.fonttype'] = 42\n",
    "p['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read the data from db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sql\n",
    "conn = sql.connect(r\".\\sqf.db\")\n",
    "c = conn.cursor()\n",
    "\n",
    "query = \"select * from cleanedsqf_1416\"\n",
    "\n",
    "dataRaw = pd.read_sql(query, conn)\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "dataRaw = dataRaw.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(dataRaw.columns)\n",
    "cols[cols.index('datestop')] = 'month'\n",
    "dataRaw.columns = cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add cpi and market index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = pd.read_excel(r\"C:\\Users\\binxi\\Desktop\\MFE 19-20\\courses\\ORIE 4741\\project\\USCPI.xls\", index_col=0, date_parser=False)\n",
    "cpi = cpi.iloc[:, [0, 4, 5, 6, 7, 8]]\n",
    "cpi_cols = ['CPI', 'CPI_F', 'CPI_H', 'CPI_C', 'CPI_T', 'CPI_M']\n",
    "cpi.columns = cpi_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift to use available data\n",
    "cpi = cpi.shift(1).dropna()\n",
    "idx = [str(i)[:7] for i in list(cpi.index)]\n",
    "cpi.index = idx\n",
    "cpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw['ym'] = dataRaw['year'].apply(lambda x: str(x) + '-') + dataRaw['month'].apply(lambda x: str(x).rjust(2, '0'))\n",
    "dataRaw = dataRaw.set_index('ym')\n",
    "dataRaw = dataRaw.join(cpi, how='left')\n",
    "dataRaw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_excel(r\"C:\\Users\\binxi\\Desktop\\MFE 19-20\\courses\\ORIE 4741\\project\\SP500.xlsx\", index_col=0, date_parser=False)\n",
    "sp = sp.iloc[:, [3]]\n",
    "sp.columns = ['SP500']\n",
    "sp = sp.resample('M').mean()\n",
    "idx = [str(i)[:7] for i in list(sp.index)]\n",
    "sp.index = idx\n",
    "sp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw.join(sp, how='left')\n",
    "dataRaw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observe missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw.replace(' ', np.nan)\n",
    "dataRaw = dataRaw.replace('**', np.nan)\n",
    "nullOb = dataRaw.isnull().sum()\n",
    "nullOb[nullOb != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw.dropna()\n",
    "print (np.shape(dataRaw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop samples with useless info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw.loc[(dataRaw['haircolr'] != 'XX') & (dataRaw['eyecolor'] != 'XX')]\n",
    "dataRaw = dataRaw.loc[(dataRaw['sex'] != 'Z') & (dataRaw['build'] != 'Z')]\n",
    "dataRaw = dataRaw.loc[dataRaw['race'] != 'U']\n",
    "print (np.shape(dataRaw))\n",
    "print (dataRaw['arstmade'].value_counts())\n",
    "print (dataRaw['sex'].value_counts())\n",
    "print (dataRaw['race'].value_counts())\n",
    "print (dataRaw['haircolr'].value_counts())\n",
    "print (dataRaw['eyecolor'].value_counts())\n",
    "print (dataRaw['build'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check feature data type and distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print (i, j, end='\\t\\t') for i, j in dataRaw.dtypes.iteritems()]\n",
    "for col in cols[cols.index('radio'):cols.index('perstop')+1]:\n",
    "    dataRaw.loc[:, col] = dataRaw.loc[:, col].astype('int64')\n",
    "dataRaw.describe()\n",
    "# information except sex, haircolor, eyecolor, build, race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = dataRaw.drop('machgun', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterOutPercentile(dataRaw, col, perc):\n",
    "    LB = np.percentile(dataRaw[col], perc)\n",
    "    UB = np.percentile(dataRaw[col], 100-perc)\n",
    "    dataRaw = dataRaw[(dataRaw[col] >= LB) & (dataRaw[col] < UB)]\n",
    "    print (np.shape(dataRaw))\n",
    "    return dataRaw\n",
    "\n",
    "dataRaw = filterOutPercentile(dataRaw, 'age', .3)\n",
    "dataRaw = filterOutPercentile(dataRaw, 'ht', .5)\n",
    "dataRaw = filterOutPercentile(dataRaw, 'weight', .5)\n",
    "dataRaw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataClean = dataRaw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read cleaned data directly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arstmade int64\t\ttimestop int64\t\tinout int64\t\tcrimsusp int64\t\toffunif int64\t\tfrisked int64\t\tsearched int64\t\tcontrabn int64\t\tpistol int64\t\triflshot int64\t\tasltweap int64\t\tknifcuti int64\t\tothrweap int64\t\taddrpct int64\t\tsex object\t\trace object\t\tage float64\t\tweight float64\t\thaircolr object\t\teyecolor object\t\tbuild object\t\tht float64\t\tyear int64\t\tmonth int64\t\tradio int64\t\tac_rept int64\t\tac_inves int64\t\trf_vcrim int64\t\trf_othsw int64\t\tac_proxm int64\t\trf_attir int64\t\tcs_objcs int64\t\tcs_descr int64\t\tcs_casng int64\t\tcs_lkout int64\t\trf_vcact int64\t\tcs_cloth int64\t\tcs_drgtr int64\t\tac_evasv int64\t\tac_assoc int64\t\tcs_furtv int64\t\trf_rfcmp int64\t\tac_cgdir int64\t\trf_verbl int64\t\tcs_vcrim int64\t\tcs_bulge int64\t\tcs_other int64\t\tac_incid int64\t\tac_time int64\t\trf_knowl int64\t\tac_stsnd int64\t\tac_other int64\t\tsb_hdobj int64\t\tsb_outln int64\t\tsb_admis int64\t\tsb_other int64\t\texplnstp int64\t\tothpers int64\t\tsumissue int64\t\tperobs int64\t\tperstop int64\t\ttypeofid object\t\tCPI float64\t\tCPI_F float64\t\tCPI_H float64\t\tCPI_C float64\t\tCPI_T float64\t\tCPI_M float64\t\tSP500 float64\t\t"
     ]
    }
   ],
   "source": [
    "#dataClean.to_csv(r\".\\DC.csv\")\n",
    "dataClean = pd.read_csv(r\".\\DC.csv\", index_col=0)\n",
    "[print (i, j, end='\\t\\t') for i, j in dataClean.dtypes.iteritems()];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "cols_all = set(dataClean.columns)\n",
    "\n",
    "cats = ['crimsusp',\n",
    "        'addrpct', 'sex', 'race',\n",
    "        'haircolr', 'eyecolor', 'build',\n",
    "        'typeofid']\n",
    "cats = set(cats)\n",
    "\n",
    "conts = cols_all - cats\n",
    "\n",
    "def getGenCorr(a, b):\n",
    "    if a == b:\n",
    "        return 1\n",
    "    if (a in conts and b in conts):\n",
    "        return dataClean.loc[:, [a, b]].corr().iloc[0, 1]\n",
    "    data = dataClean.loc[:, [a, b]].groupby([a, b]).size().reset_index()\n",
    "    #print (data)\n",
    "    data = data.pivot_table(index=a, values=0, columns=b).fillna(0)\n",
    "    #print (data, np.shape(data))\n",
    "    chi2 = stats.chi2_contingency(data)[0]\n",
    "    den = min(np.shape(data))-1\n",
    "    return np.sqrt((chi2/len(dataClean))/den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = pd.DataFrame(index=cats, columns=cats)\n",
    "visited = []\n",
    "\n",
    "for a in cols_all:\n",
    "    for b in cols_all:\n",
    "        if (b, a) not in visited:\n",
    "            corrs.loc[a, b] = getGenCorr(a, b)\n",
    "        else:\n",
    "            corrs.loc[a, b] = corrs.loc[b, a]\n",
    "        visited.append((a, b))   \n",
    "corrs = corrs.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['arstmade', 'sb_other', 'searched', 'contrabn', 'addrpct', 'crimsusp',\n",
       "       'inout', 'knifcuti', 'rf_othsw', 'pistol', 'sb_admis', 'othrweap',\n",
       "       'sb_outln', 'cs_casng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_fhm = abs(corrs['arstmade']).sort_values(ascending=False)[:14].index\n",
    "chosen_fhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arstmade</th>\n",
       "      <th>sb_other</th>\n",
       "      <th>searched</th>\n",
       "      <th>contrabn</th>\n",
       "      <th>addrpct</th>\n",
       "      <th>crimsusp</th>\n",
       "      <th>inout</th>\n",
       "      <th>knifcuti</th>\n",
       "      <th>rf_othsw</th>\n",
       "      <th>pistol</th>\n",
       "      <th>sb_admis</th>\n",
       "      <th>othrweap</th>\n",
       "      <th>sb_outln</th>\n",
       "      <th>cs_casng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>arstmade</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.527290</td>\n",
       "      <td>0.509582</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.318247</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.247351</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>0.172820</td>\n",
       "      <td>0.154133</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>0.125859</td>\n",
       "      <td>0.112431</td>\n",
       "      <td>-0.107955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_other</td>\n",
       "      <td>0.527290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731838</td>\n",
       "      <td>0.269184</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.161593</td>\n",
       "      <td>0.155392</td>\n",
       "      <td>0.076631</td>\n",
       "      <td>0.265022</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>-0.003165</td>\n",
       "      <td>0.064866</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>-0.086912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>searched</td>\n",
       "      <td>0.509582</td>\n",
       "      <td>0.731838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>0.198263</td>\n",
       "      <td>0.140888</td>\n",
       "      <td>0.116884</td>\n",
       "      <td>0.242640</td>\n",
       "      <td>0.235103</td>\n",
       "      <td>0.135679</td>\n",
       "      <td>0.222794</td>\n",
       "      <td>0.133894</td>\n",
       "      <td>0.233993</td>\n",
       "      <td>-0.091698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>contrabn</td>\n",
       "      <td>0.377584</td>\n",
       "      <td>0.269184</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152516</td>\n",
       "      <td>0.144637</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>0.071717</td>\n",
       "      <td>0.096647</td>\n",
       "      <td>0.089137</td>\n",
       "      <td>0.065123</td>\n",
       "      <td>0.037016</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>-0.046165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct</td>\n",
       "      <td>0.318247</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.198263</td>\n",
       "      <td>0.152516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145123</td>\n",
       "      <td>0.381859</td>\n",
       "      <td>0.170510</td>\n",
       "      <td>0.174244</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>0.066762</td>\n",
       "      <td>0.093557</td>\n",
       "      <td>0.289638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp</td>\n",
       "      <td>0.254448</td>\n",
       "      <td>0.161593</td>\n",
       "      <td>0.140888</td>\n",
       "      <td>0.144637</td>\n",
       "      <td>0.145123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.372498</td>\n",
       "      <td>0.117484</td>\n",
       "      <td>0.158820</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.071358</td>\n",
       "      <td>0.083537</td>\n",
       "      <td>0.279894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inout</td>\n",
       "      <td>0.247351</td>\n",
       "      <td>0.155392</td>\n",
       "      <td>0.116884</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>0.381859</td>\n",
       "      <td>0.372498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049975</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>-0.089260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>knifcuti</td>\n",
       "      <td>0.223633</td>\n",
       "      <td>0.076631</td>\n",
       "      <td>0.242640</td>\n",
       "      <td>0.071717</td>\n",
       "      <td>0.170510</td>\n",
       "      <td>0.117484</td>\n",
       "      <td>0.049975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>-0.004911</td>\n",
       "      <td>0.364220</td>\n",
       "      <td>0.090611</td>\n",
       "      <td>0.219842</td>\n",
       "      <td>-0.054823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_othsw</td>\n",
       "      <td>0.172820</td>\n",
       "      <td>0.265022</td>\n",
       "      <td>0.235103</td>\n",
       "      <td>0.096647</td>\n",
       "      <td>0.174244</td>\n",
       "      <td>0.158820</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>0.076674</td>\n",
       "      <td>0.068671</td>\n",
       "      <td>0.049171</td>\n",
       "      <td>-0.112704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pistol</td>\n",
       "      <td>0.154133</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>0.135679</td>\n",
       "      <td>0.089137</td>\n",
       "      <td>0.081636</td>\n",
       "      <td>0.054633</td>\n",
       "      <td>-0.005883</td>\n",
       "      <td>-0.004911</td>\n",
       "      <td>0.041910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>0.035167</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>-0.032731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_admis</td>\n",
       "      <td>0.143137</td>\n",
       "      <td>-0.003165</td>\n",
       "      <td>0.222794</td>\n",
       "      <td>0.065123</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>0.058718</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.364220</td>\n",
       "      <td>0.076674</td>\n",
       "      <td>0.079725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145908</td>\n",
       "      <td>0.075721</td>\n",
       "      <td>-0.031229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>othrweap</td>\n",
       "      <td>0.125859</td>\n",
       "      <td>0.064866</td>\n",
       "      <td>0.133894</td>\n",
       "      <td>0.037016</td>\n",
       "      <td>0.066762</td>\n",
       "      <td>0.071358</td>\n",
       "      <td>0.006288</td>\n",
       "      <td>0.090611</td>\n",
       "      <td>0.068671</td>\n",
       "      <td>0.035167</td>\n",
       "      <td>0.145908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110377</td>\n",
       "      <td>-0.035562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_outln</td>\n",
       "      <td>0.112431</td>\n",
       "      <td>-0.000662</td>\n",
       "      <td>0.233993</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>0.093557</td>\n",
       "      <td>0.083537</td>\n",
       "      <td>0.012845</td>\n",
       "      <td>0.219842</td>\n",
       "      <td>0.049171</td>\n",
       "      <td>0.167963</td>\n",
       "      <td>0.075721</td>\n",
       "      <td>0.110377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.031457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_casng</td>\n",
       "      <td>-0.107955</td>\n",
       "      <td>-0.086912</td>\n",
       "      <td>-0.091698</td>\n",
       "      <td>-0.046165</td>\n",
       "      <td>0.289638</td>\n",
       "      <td>0.279894</td>\n",
       "      <td>-0.089260</td>\n",
       "      <td>-0.054823</td>\n",
       "      <td>-0.112704</td>\n",
       "      <td>-0.032731</td>\n",
       "      <td>-0.031229</td>\n",
       "      <td>-0.035562</td>\n",
       "      <td>-0.031457</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          arstmade  sb_other  searched  contrabn   addrpct  crimsusp  \\\n",
       "arstmade  1.000000  0.527290  0.509582  0.377584  0.318247  0.254448   \n",
       "sb_other  0.527290  1.000000  0.731838  0.269184  0.199996  0.161593   \n",
       "searched  0.509582  0.731838  1.000000  0.274575  0.198263  0.140888   \n",
       "contrabn  0.377584  0.269184  0.274575  1.000000  0.152516  0.144637   \n",
       "addrpct   0.318247  0.199996  0.198263  0.152516  1.000000  0.145123   \n",
       "crimsusp  0.254448  0.161593  0.140888  0.144637  0.145123  1.000000   \n",
       "inout     0.247351  0.155392  0.116884  0.065836  0.381859  0.372498   \n",
       "knifcuti  0.223633  0.076631  0.242640  0.071717  0.170510  0.117484   \n",
       "rf_othsw  0.172820  0.265022  0.235103  0.096647  0.174244  0.158820   \n",
       "pistol    0.154133  0.070176  0.135679  0.089137  0.081636  0.054633   \n",
       "sb_admis  0.143137 -0.003165  0.222794  0.065123  0.078421  0.058718   \n",
       "othrweap  0.125859  0.064866  0.133894  0.037016  0.066762  0.071358   \n",
       "sb_outln  0.112431 -0.000662  0.233993  0.040007  0.093557  0.083537   \n",
       "cs_casng -0.107955 -0.086912 -0.091698 -0.046165  0.289638  0.279894   \n",
       "\n",
       "             inout  knifcuti  rf_othsw    pistol  sb_admis  othrweap  \\\n",
       "arstmade  0.247351  0.223633  0.172820  0.154133  0.143137  0.125859   \n",
       "sb_other  0.155392  0.076631  0.265022  0.070176 -0.003165  0.064866   \n",
       "searched  0.116884  0.242640  0.235103  0.135679  0.222794  0.133894   \n",
       "contrabn  0.065836  0.071717  0.096647  0.089137  0.065123  0.037016   \n",
       "addrpct   0.381859  0.170510  0.174244  0.081636  0.078421  0.066762   \n",
       "crimsusp  0.372498  0.117484  0.158820  0.054633  0.058718  0.071358   \n",
       "inout     1.000000  0.049975  0.072851 -0.005883  0.000992  0.006288   \n",
       "knifcuti  0.049975  1.000000  0.113583 -0.004911  0.364220  0.090611   \n",
       "rf_othsw  0.072851  0.113583  1.000000  0.041910  0.076674  0.068671   \n",
       "pistol   -0.005883 -0.004911  0.041910  1.000000  0.079725  0.035167   \n",
       "sb_admis  0.000992  0.364220  0.076674  0.079725  1.000000  0.145908   \n",
       "othrweap  0.006288  0.090611  0.068671  0.035167  0.145908  1.000000   \n",
       "sb_outln  0.012845  0.219842  0.049171  0.167963  0.075721  0.110377   \n",
       "cs_casng -0.089260 -0.054823 -0.112704 -0.032731 -0.031229 -0.035562   \n",
       "\n",
       "          sb_outln  cs_casng  \n",
       "arstmade  0.112431 -0.107955  \n",
       "sb_other -0.000662 -0.086912  \n",
       "searched  0.233993 -0.091698  \n",
       "contrabn  0.040007 -0.046165  \n",
       "addrpct   0.093557  0.289638  \n",
       "crimsusp  0.083537  0.279894  \n",
       "inout     0.012845 -0.089260  \n",
       "knifcuti  0.219842 -0.054823  \n",
       "rf_othsw  0.049171 -0.112704  \n",
       "pistol    0.167963 -0.032731  \n",
       "sb_admis  0.075721 -0.031229  \n",
       "othrweap  0.110377 -0.035562  \n",
       "sb_outln  1.000000 -0.031457  \n",
       "cs_casng -0.031457  1.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_chosen = corrs[chosen_fhm].loc[chosen_fhm]\n",
    "corr_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x691.2 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pdf = PdfPages(r'.\\figures\\Figure_hm_1416.pdf')\n",
    "figure, ax = plt.subplots(figsize=(12,12*0.8))\n",
    "figure.tight_layout()\n",
    "sns.heatmap(corrs[chosen_fhm].loc[chosen_fhm], vmin=-0.1, vmax=1, linewidths=1, square=True, ax=ax)\n",
    "#ax.set_yticklabels(labels=corrs.index, rotation=0)\n",
    "#ax.set_xticklabels(labels=corrs.columns, rotation=90)\n",
    "pdf.savefig(figure,bbox_inches='tight',dpi=figure.dpi,pad_inches=0.0)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = [ 'crimsusp','addrpct', 'sex', 'race',\n",
    "        'haircolr', 'eyecolor', 'build', 'typeofid']\n",
    "for cat in drops[:]:\n",
    "    temp = pd.get_dummies(dataClean[cat], prefix=cat)\n",
    "    dataClean = dataClean.drop(cat, 1)\n",
    "    dataClean = pd.concat([dataClean, temp], axis=1)\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestop\n",
    "timestop = dataClean.loc[:, ['timestop']]/60\n",
    "timestop['timestop2'] = timestop**2\n",
    "timestop['timestop3'] = timestop.iloc[:, 0]**2\n",
    "dataClean = dataClean.drop('timestop', 1)\n",
    "dataClean = pd.concat([dataClean, timestop], axis=1)\n",
    "del timestop\n",
    "\n",
    "cpi_poly = dataClean.loc[:, ['CPI']]\n",
    "cpi_poly['CPI2'] = cpi_poly**2\n",
    "\n",
    "sp500_poly = dataClean.loc[:, ['SP500']] \n",
    "sp500_poly['sp2'] = sp500_poly**2\n",
    "\n",
    "dataClean = dataClean.drop(['CPI', 'SP500'], 1)\n",
    "dataClean = pd.concat([dataClean, cpi_poly, sp500_poly], axis=1)\n",
    "\n",
    "del cpi_poly, sp500_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge columns\n",
    "#### after one-hot, there are few data in some categories, merge them with other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['riflshot', 'asltweap', 'crimsusp_1', 'crimsusp_2', 'crimsusp_5',\n",
       "       'crimsusp_7', 'crimsusp_15', 'crimsusp_19', 'crimsusp_25',\n",
       "       'crimsusp_26', 'crimsusp_27', 'crimsusp_40', 'crimsusp_41',\n",
       "       'crimsusp_42', 'crimsusp_44', 'crimsusp_45', 'crimsusp_46',\n",
       "       'crimsusp_47', 'crimsusp_48', 'crimsusp_51', 'crimsusp_52',\n",
       "       'crimsusp_54', 'crimsusp_55', 'crimsusp_56', 'crimsusp_58',\n",
       "       'haircolr_SN', 'eyecolor_MA', 'eyecolor_P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen = dataClean.sum(0).loc[dataClean.sum(0)<10].index\n",
    "data_crim = dataClean.loc[:, chosen[2:-3]].sum(1)\n",
    "dataClean['crimsusp_other'] = data_crim\n",
    "dataClean = dataClean.drop(chosen[2:-3], 1)\n",
    "                           \n",
    "dataClean['eyecolor_Z'] = dataClean['eyecolor_Z'] + dataClean['eyecolor_MA'] + dataClean['eyecolor_P']\n",
    "dataClean['haircolr_ZZ'] = dataClean['haircolr_ZZ'] + dataClean['haircolr_SN']                          \n",
    "\n",
    "dataClean = dataClean.drop(chosen[-3:], 1)\n",
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65343, 209)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arstmade</th>\n",
       "      <th>inout</th>\n",
       "      <th>offunif</th>\n",
       "      <th>frisked</th>\n",
       "      <th>searched</th>\n",
       "      <th>contrabn</th>\n",
       "      <th>pistol</th>\n",
       "      <th>riflshot</th>\n",
       "      <th>asltweap</th>\n",
       "      <th>knifcuti</th>\n",
       "      <th>othrweap</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>ht</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>radio</th>\n",
       "      <th>ac_rept</th>\n",
       "      <th>ac_inves</th>\n",
       "      <th>rf_vcrim</th>\n",
       "      <th>rf_othsw</th>\n",
       "      <th>ac_proxm</th>\n",
       "      <th>rf_attir</th>\n",
       "      <th>cs_objcs</th>\n",
       "      <th>cs_descr</th>\n",
       "      <th>cs_casng</th>\n",
       "      <th>cs_lkout</th>\n",
       "      <th>rf_vcact</th>\n",
       "      <th>cs_cloth</th>\n",
       "      <th>cs_drgtr</th>\n",
       "      <th>ac_evasv</th>\n",
       "      <th>ac_assoc</th>\n",
       "      <th>cs_furtv</th>\n",
       "      <th>rf_rfcmp</th>\n",
       "      <th>ac_cgdir</th>\n",
       "      <th>rf_verbl</th>\n",
       "      <th>cs_vcrim</th>\n",
       "      <th>cs_bulge</th>\n",
       "      <th>cs_other</th>\n",
       "      <th>ac_incid</th>\n",
       "      <th>ac_time</th>\n",
       "      <th>rf_knowl</th>\n",
       "      <th>ac_stsnd</th>\n",
       "      <th>ac_other</th>\n",
       "      <th>sb_hdobj</th>\n",
       "      <th>sb_outln</th>\n",
       "      <th>sb_admis</th>\n",
       "      <th>sb_other</th>\n",
       "      <th>explnstp</th>\n",
       "      <th>othpers</th>\n",
       "      <th>sumissue</th>\n",
       "      <th>perobs</th>\n",
       "      <th>perstop</th>\n",
       "      <th>CPI_F</th>\n",
       "      <th>CPI_H</th>\n",
       "      <th>CPI_C</th>\n",
       "      <th>CPI_T</th>\n",
       "      <th>CPI_M</th>\n",
       "      <th>crimsusp_3</th>\n",
       "      <th>crimsusp_4</th>\n",
       "      <th>crimsusp_6</th>\n",
       "      <th>crimsusp_8</th>\n",
       "      <th>crimsusp_9</th>\n",
       "      <th>crimsusp_10</th>\n",
       "      <th>crimsusp_11</th>\n",
       "      <th>crimsusp_12</th>\n",
       "      <th>crimsusp_13</th>\n",
       "      <th>crimsusp_14</th>\n",
       "      <th>crimsusp_16</th>\n",
       "      <th>crimsusp_17</th>\n",
       "      <th>crimsusp_18</th>\n",
       "      <th>crimsusp_20</th>\n",
       "      <th>crimsusp_21</th>\n",
       "      <th>crimsusp_22</th>\n",
       "      <th>crimsusp_23</th>\n",
       "      <th>crimsusp_24</th>\n",
       "      <th>crimsusp_28</th>\n",
       "      <th>crimsusp_29</th>\n",
       "      <th>crimsusp_31</th>\n",
       "      <th>crimsusp_32</th>\n",
       "      <th>crimsusp_33</th>\n",
       "      <th>crimsusp_34</th>\n",
       "      <th>crimsusp_36</th>\n",
       "      <th>crimsusp_37</th>\n",
       "      <th>crimsusp_38</th>\n",
       "      <th>crimsusp_39</th>\n",
       "      <th>crimsusp_43</th>\n",
       "      <th>crimsusp_49</th>\n",
       "      <th>crimsusp_50</th>\n",
       "      <th>crimsusp_53</th>\n",
       "      <th>addrpct_1</th>\n",
       "      <th>addrpct_5</th>\n",
       "      <th>addrpct_6</th>\n",
       "      <th>addrpct_7</th>\n",
       "      <th>addrpct_9</th>\n",
       "      <th>addrpct_10</th>\n",
       "      <th>addrpct_13</th>\n",
       "      <th>addrpct_14</th>\n",
       "      <th>addrpct_17</th>\n",
       "      <th>addrpct_18</th>\n",
       "      <th>addrpct_19</th>\n",
       "      <th>addrpct_20</th>\n",
       "      <th>addrpct_22</th>\n",
       "      <th>addrpct_23</th>\n",
       "      <th>addrpct_24</th>\n",
       "      <th>addrpct_25</th>\n",
       "      <th>addrpct_26</th>\n",
       "      <th>addrpct_28</th>\n",
       "      <th>addrpct_30</th>\n",
       "      <th>addrpct_32</th>\n",
       "      <th>addrpct_33</th>\n",
       "      <th>addrpct_34</th>\n",
       "      <th>addrpct_40</th>\n",
       "      <th>addrpct_41</th>\n",
       "      <th>addrpct_42</th>\n",
       "      <th>addrpct_43</th>\n",
       "      <th>addrpct_44</th>\n",
       "      <th>addrpct_45</th>\n",
       "      <th>addrpct_46</th>\n",
       "      <th>addrpct_47</th>\n",
       "      <th>addrpct_48</th>\n",
       "      <th>addrpct_49</th>\n",
       "      <th>addrpct_50</th>\n",
       "      <th>addrpct_52</th>\n",
       "      <th>addrpct_60</th>\n",
       "      <th>addrpct_61</th>\n",
       "      <th>addrpct_62</th>\n",
       "      <th>addrpct_63</th>\n",
       "      <th>addrpct_66</th>\n",
       "      <th>addrpct_67</th>\n",
       "      <th>addrpct_68</th>\n",
       "      <th>addrpct_69</th>\n",
       "      <th>addrpct_70</th>\n",
       "      <th>addrpct_71</th>\n",
       "      <th>addrpct_72</th>\n",
       "      <th>addrpct_73</th>\n",
       "      <th>addrpct_75</th>\n",
       "      <th>addrpct_76</th>\n",
       "      <th>addrpct_77</th>\n",
       "      <th>addrpct_78</th>\n",
       "      <th>addrpct_79</th>\n",
       "      <th>addrpct_81</th>\n",
       "      <th>addrpct_83</th>\n",
       "      <th>addrpct_84</th>\n",
       "      <th>addrpct_88</th>\n",
       "      <th>addrpct_90</th>\n",
       "      <th>addrpct_94</th>\n",
       "      <th>addrpct_100</th>\n",
       "      <th>addrpct_101</th>\n",
       "      <th>addrpct_102</th>\n",
       "      <th>addrpct_103</th>\n",
       "      <th>addrpct_104</th>\n",
       "      <th>addrpct_105</th>\n",
       "      <th>addrpct_106</th>\n",
       "      <th>addrpct_107</th>\n",
       "      <th>addrpct_108</th>\n",
       "      <th>addrpct_109</th>\n",
       "      <th>addrpct_110</th>\n",
       "      <th>addrpct_111</th>\n",
       "      <th>addrpct_112</th>\n",
       "      <th>addrpct_113</th>\n",
       "      <th>addrpct_114</th>\n",
       "      <th>addrpct_115</th>\n",
       "      <th>addrpct_120</th>\n",
       "      <th>addrpct_121</th>\n",
       "      <th>addrpct_122</th>\n",
       "      <th>addrpct_123</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>race_A</th>\n",
       "      <th>race_B</th>\n",
       "      <th>race_I</th>\n",
       "      <th>race_P</th>\n",
       "      <th>race_Q</th>\n",
       "      <th>race_W</th>\n",
       "      <th>race_Z</th>\n",
       "      <th>haircolr_BA</th>\n",
       "      <th>haircolr_BK</th>\n",
       "      <th>haircolr_BL</th>\n",
       "      <th>haircolr_BR</th>\n",
       "      <th>haircolr_DY</th>\n",
       "      <th>haircolr_GY</th>\n",
       "      <th>haircolr_RA</th>\n",
       "      <th>haircolr_SP</th>\n",
       "      <th>haircolr_ZZ</th>\n",
       "      <th>eyecolor_BK</th>\n",
       "      <th>eyecolor_BL</th>\n",
       "      <th>eyecolor_BR</th>\n",
       "      <th>eyecolor_DF</th>\n",
       "      <th>eyecolor_GR</th>\n",
       "      <th>eyecolor_GY</th>\n",
       "      <th>eyecolor_HA</th>\n",
       "      <th>eyecolor_Z</th>\n",
       "      <th>build_H</th>\n",
       "      <th>build_M</th>\n",
       "      <th>build_T</th>\n",
       "      <th>build_U</th>\n",
       "      <th>typeofid_O</th>\n",
       "      <th>typeofid_P</th>\n",
       "      <th>typeofid_R</th>\n",
       "      <th>typeofid_V</th>\n",
       "      <th>timestop</th>\n",
       "      <th>timestop2</th>\n",
       "      <th>timestop3</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPI2</th>\n",
       "      <th>SP500</th>\n",
       "      <th>sp2</th>\n",
       "      <th>crimsusp_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.00000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>65343.000000</td>\n",
       "      <td>6.534300e+04</td>\n",
       "      <td>65343.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.170072</td>\n",
       "      <td>0.195706</td>\n",
       "      <td>0.561269</td>\n",
       "      <td>0.663973</td>\n",
       "      <td>0.182682</td>\n",
       "      <td>0.047289</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>27.868249</td>\n",
       "      <td>169.814839</td>\n",
       "      <td>68.799458</td>\n",
       "      <td>2014.671625</td>\n",
       "      <td>5.369267</td>\n",
       "      <td>0.399109</td>\n",
       "      <td>0.250448</td>\n",
       "      <td>0.136510</td>\n",
       "      <td>0.227293</td>\n",
       "      <td>0.139617</td>\n",
       "      <td>0.326676</td>\n",
       "      <td>0.072066</td>\n",
       "      <td>0.035168</td>\n",
       "      <td>0.336471</td>\n",
       "      <td>0.234379</td>\n",
       "      <td>0.121712</td>\n",
       "      <td>0.079519</td>\n",
       "      <td>0.045039</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>0.194527</td>\n",
       "      <td>0.069877</td>\n",
       "      <td>0.325896</td>\n",
       "      <td>0.116768</td>\n",
       "      <td>0.223390</td>\n",
       "      <td>0.009810</td>\n",
       "      <td>0.091502</td>\n",
       "      <td>0.075632</td>\n",
       "      <td>0.335093</td>\n",
       "      <td>0.476225</td>\n",
       "      <td>0.350321</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.099261</td>\n",
       "      <td>0.064414</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>0.106913</td>\n",
       "      <td>0.998714</td>\n",
       "      <td>0.277689</td>\n",
       "      <td>0.027608</td>\n",
       "      <td>2.599590</td>\n",
       "      <td>7.876697</td>\n",
       "      <td>243.872676</td>\n",
       "      <td>235.478761</td>\n",
       "      <td>126.929066</td>\n",
       "      <td>207.052416</td>\n",
       "      <td>441.771970</td>\n",
       "      <td>0.022910</td>\n",
       "      <td>0.039775</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.014309</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.112682</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.390049</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.032123</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.028878</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.191206</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.059272</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.023063</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.002556</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007453</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.011340</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.008509</td>\n",
       "      <td>0.005724</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.017064</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>0.017569</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.026782</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.014722</td>\n",
       "      <td>0.022849</td>\n",
       "      <td>0.008448</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.021563</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.005418</td>\n",
       "      <td>0.013284</td>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.020262</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.017324</td>\n",
       "      <td>0.021257</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.007621</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.025481</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.011401</td>\n",
       "      <td>0.016299</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.019727</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.030516</td>\n",
       "      <td>0.063802</td>\n",
       "      <td>0.024012</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.015977</td>\n",
       "      <td>0.007331</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.011417</td>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.027470</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.036806</td>\n",
       "      <td>0.031511</td>\n",
       "      <td>0.018931</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.064950</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.053196</td>\n",
       "      <td>0.529621</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.063863</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.115973</td>\n",
       "      <td>0.009703</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.736207</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.206663</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.065133</td>\n",
       "      <td>0.018946</td>\n",
       "      <td>0.895459</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.088441</td>\n",
       "      <td>0.518877</td>\n",
       "      <td>0.385183</td>\n",
       "      <td>0.007499</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>0.586872</td>\n",
       "      <td>0.022237</td>\n",
       "      <td>0.372312</td>\n",
       "      <td>14.057254</td>\n",
       "      <td>257.761544</td>\n",
       "      <td>257.761544</td>\n",
       "      <td>236.678826</td>\n",
       "      <td>56021.351326</td>\n",
       "      <td>1979.688236</td>\n",
       "      <td>3.931457e+06</td>\n",
       "      <td>0.001347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.375699</td>\n",
       "      <td>0.396746</td>\n",
       "      <td>0.496236</td>\n",
       "      <td>0.472352</td>\n",
       "      <td>0.386409</td>\n",
       "      <td>0.212258</td>\n",
       "      <td>0.082974</td>\n",
       "      <td>0.009582</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.162741</td>\n",
       "      <td>0.101260</td>\n",
       "      <td>11.176890</td>\n",
       "      <td>28.845242</td>\n",
       "      <td>3.046380</td>\n",
       "      <td>0.755613</td>\n",
       "      <td>3.402402</td>\n",
       "      <td>0.489719</td>\n",
       "      <td>0.433274</td>\n",
       "      <td>0.343332</td>\n",
       "      <td>0.419087</td>\n",
       "      <td>0.346592</td>\n",
       "      <td>0.469001</td>\n",
       "      <td>0.258599</td>\n",
       "      <td>0.184206</td>\n",
       "      <td>0.472506</td>\n",
       "      <td>0.423613</td>\n",
       "      <td>0.326955</td>\n",
       "      <td>0.270549</td>\n",
       "      <td>0.207392</td>\n",
       "      <td>0.250686</td>\n",
       "      <td>0.395839</td>\n",
       "      <td>0.254942</td>\n",
       "      <td>0.468712</td>\n",
       "      <td>0.321147</td>\n",
       "      <td>0.416521</td>\n",
       "      <td>0.098558</td>\n",
       "      <td>0.288324</td>\n",
       "      <td>0.264410</td>\n",
       "      <td>0.472027</td>\n",
       "      <td>0.499438</td>\n",
       "      <td>0.477074</td>\n",
       "      <td>0.219295</td>\n",
       "      <td>0.167552</td>\n",
       "      <td>0.299014</td>\n",
       "      <td>0.245491</td>\n",
       "      <td>0.109289</td>\n",
       "      <td>0.104176</td>\n",
       "      <td>0.309005</td>\n",
       "      <td>0.035831</td>\n",
       "      <td>0.447862</td>\n",
       "      <td>0.163849</td>\n",
       "      <td>7.016901</td>\n",
       "      <td>7.574259</td>\n",
       "      <td>3.512057</td>\n",
       "      <td>4.565384</td>\n",
       "      <td>2.596709</td>\n",
       "      <td>10.639750</td>\n",
       "      <td>10.961925</td>\n",
       "      <td>0.149617</td>\n",
       "      <td>0.195431</td>\n",
       "      <td>0.020696</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.118763</td>\n",
       "      <td>0.038698</td>\n",
       "      <td>0.316206</td>\n",
       "      <td>0.078195</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>0.487765</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.015646</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>0.176328</td>\n",
       "      <td>0.046073</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.167466</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.031524</td>\n",
       "      <td>0.393254</td>\n",
       "      <td>0.016595</td>\n",
       "      <td>0.236135</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.021062</td>\n",
       "      <td>0.029263</td>\n",
       "      <td>0.234499</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>0.031766</td>\n",
       "      <td>0.150105</td>\n",
       "      <td>0.023789</td>\n",
       "      <td>0.050490</td>\n",
       "      <td>0.080668</td>\n",
       "      <td>0.044730</td>\n",
       "      <td>0.086009</td>\n",
       "      <td>0.108947</td>\n",
       "      <td>0.065321</td>\n",
       "      <td>0.105885</td>\n",
       "      <td>0.112120</td>\n",
       "      <td>0.064030</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.091851</td>\n",
       "      <td>0.075439</td>\n",
       "      <td>0.043170</td>\n",
       "      <td>0.129510</td>\n",
       "      <td>0.083608</td>\n",
       "      <td>0.131379</td>\n",
       "      <td>0.066358</td>\n",
       "      <td>0.082335</td>\n",
       "      <td>0.07268</td>\n",
       "      <td>0.108947</td>\n",
       "      <td>0.074632</td>\n",
       "      <td>0.091029</td>\n",
       "      <td>0.161446</td>\n",
       "      <td>0.142503</td>\n",
       "      <td>0.108328</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>0.149422</td>\n",
       "      <td>0.091523</td>\n",
       "      <td>0.090531</td>\n",
       "      <td>0.117694</td>\n",
       "      <td>0.063195</td>\n",
       "      <td>0.145253</td>\n",
       "      <td>0.085128</td>\n",
       "      <td>0.109221</td>\n",
       "      <td>0.135523</td>\n",
       "      <td>0.073405</td>\n",
       "      <td>0.114488</td>\n",
       "      <td>0.080104</td>\n",
       "      <td>0.140897</td>\n",
       "      <td>0.168453</td>\n",
       "      <td>0.059353</td>\n",
       "      <td>0.099014</td>\n",
       "      <td>0.126095</td>\n",
       "      <td>0.109425</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>0.144241</td>\n",
       "      <td>0.099392</td>\n",
       "      <td>0.086968</td>\n",
       "      <td>0.065784</td>\n",
       "      <td>0.157582</td>\n",
       "      <td>0.080386</td>\n",
       "      <td>0.106168</td>\n",
       "      <td>0.126622</td>\n",
       "      <td>0.079631</td>\n",
       "      <td>0.120932</td>\n",
       "      <td>0.059608</td>\n",
       "      <td>0.073919</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.157351</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.089780</td>\n",
       "      <td>0.172003</td>\n",
       "      <td>0.244401</td>\n",
       "      <td>0.153087</td>\n",
       "      <td>0.062713</td>\n",
       "      <td>0.125388</td>\n",
       "      <td>0.085305</td>\n",
       "      <td>0.101923</td>\n",
       "      <td>0.106238</td>\n",
       "      <td>0.109766</td>\n",
       "      <td>0.163451</td>\n",
       "      <td>0.080198</td>\n",
       "      <td>0.188286</td>\n",
       "      <td>0.174695</td>\n",
       "      <td>0.136282</td>\n",
       "      <td>0.080948</td>\n",
       "      <td>0.246439</td>\n",
       "      <td>0.246439</td>\n",
       "      <td>0.224426</td>\n",
       "      <td>0.499126</td>\n",
       "      <td>0.061613</td>\n",
       "      <td>0.244511</td>\n",
       "      <td>0.416815</td>\n",
       "      <td>0.320195</td>\n",
       "      <td>0.098024</td>\n",
       "      <td>0.153372</td>\n",
       "      <td>0.440692</td>\n",
       "      <td>0.113966</td>\n",
       "      <td>0.404915</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.091276</td>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.075338</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.246763</td>\n",
       "      <td>0.136336</td>\n",
       "      <td>0.305963</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.032946</td>\n",
       "      <td>0.094752</td>\n",
       "      <td>0.046238</td>\n",
       "      <td>0.283937</td>\n",
       "      <td>0.499647</td>\n",
       "      <td>0.486642</td>\n",
       "      <td>0.086271</td>\n",
       "      <td>0.135033</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.483425</td>\n",
       "      <td>7.756036</td>\n",
       "      <td>189.062376</td>\n",
       "      <td>189.062376</td>\n",
       "      <td>2.117683</td>\n",
       "      <td>1003.064109</td>\n",
       "      <td>110.868007</td>\n",
       "      <td>4.394685e+05</td>\n",
       "      <td>0.036674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>237.820000</td>\n",
       "      <td>228.892000</td>\n",
       "      <td>121.878000</td>\n",
       "      <td>187.345000</td>\n",
       "      <td>427.089000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>233.049000</td>\n",
       "      <td>54311.836401</td>\n",
       "      <td>1817.034737</td>\n",
       "      <td>3.301615e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>240.226000</td>\n",
       "      <td>231.689000</td>\n",
       "      <td>124.547000</td>\n",
       "      <td>197.145000</td>\n",
       "      <td>433.369000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.050000</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>64.802500</td>\n",
       "      <td>234.781000</td>\n",
       "      <td>55122.117961</td>\n",
       "      <td>1864.263333</td>\n",
       "      <td>3.475478e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>244.902000</td>\n",
       "      <td>234.675000</td>\n",
       "      <td>127.083000</td>\n",
       "      <td>208.012000</td>\n",
       "      <td>438.445000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>262.440000</td>\n",
       "      <td>262.440000</td>\n",
       "      <td>237.072000</td>\n",
       "      <td>56203.133184</td>\n",
       "      <td>1947.087619</td>\n",
       "      <td>3.791150e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>247.196000</td>\n",
       "      <td>239.298000</td>\n",
       "      <td>128.963000</td>\n",
       "      <td>214.673000</td>\n",
       "      <td>447.213000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>430.562500</td>\n",
       "      <td>430.562500</td>\n",
       "      <td>237.945000</td>\n",
       "      <td>56617.823025</td>\n",
       "      <td>2080.616500</td>\n",
       "      <td>4.328965e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>248.575000</td>\n",
       "      <td>246.271000</td>\n",
       "      <td>131.961000</td>\n",
       "      <td>223.392000</td>\n",
       "      <td>469.333000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.983333</td>\n",
       "      <td>575.200278</td>\n",
       "      <td>575.200278</td>\n",
       "      <td>241.729000</td>\n",
       "      <td>58432.909441</td>\n",
       "      <td>2246.629048</td>\n",
       "      <td>5.047342e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           arstmade         inout       offunif       frisked      searched  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.170072      0.195706      0.561269      0.663973      0.182682   \n",
       "std        0.375699      0.396746      0.496236      0.472352      0.386409   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           contrabn        pistol      riflshot      asltweap      knifcuti  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.047289      0.006933      0.000092      0.000046      0.027226   \n",
       "std        0.212258      0.082974      0.009582      0.006776      0.162741   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           othrweap           age        weight            ht          year  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.010361     27.868249    169.814839     68.799458   2014.671625   \n",
       "std        0.101260     11.176890     28.845242      3.046380      0.755613   \n",
       "min        0.000000     12.000000    100.000000     60.000000   2014.000000   \n",
       "25%        0.000000     20.000000    150.000000     67.000000   2014.000000   \n",
       "50%        0.000000     24.000000    170.000000     69.000000   2014.000000   \n",
       "75%        0.000000     34.000000    185.000000     71.000000   2015.000000   \n",
       "max        1.000000     72.000000    290.000000     76.000000   2016.000000   \n",
       "\n",
       "              month         radio       ac_rept      ac_inves      rf_vcrim  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       5.369267      0.399109      0.250448      0.136510      0.227293   \n",
       "std        3.402402      0.489719      0.433274      0.343332      0.419087   \n",
       "min        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        3.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        5.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        8.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "max       12.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           rf_othsw      ac_proxm      rf_attir      cs_objcs      cs_descr  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.139617      0.326676      0.072066      0.035168      0.336471   \n",
       "std        0.346592      0.469001      0.258599      0.184206      0.472506   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      1.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           cs_casng      cs_lkout      rf_vcact      cs_cloth      cs_drgtr  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.234379      0.121712      0.079519      0.045039      0.067383   \n",
       "std        0.423613      0.326955      0.270549      0.207392      0.250686   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           ac_evasv      ac_assoc      cs_furtv      rf_rfcmp      ac_cgdir  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.194527      0.069877      0.325896      0.116768      0.223390   \n",
       "std        0.395839      0.254942      0.468712      0.321147      0.416521   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           rf_verbl      cs_vcrim      cs_bulge      cs_other      ac_incid  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.009810      0.091502      0.075632      0.335093      0.476225   \n",
       "std        0.098558      0.288324      0.264410      0.472027      0.499438   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            ac_time      rf_knowl      ac_stsnd      ac_other      sb_hdobj  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.350321      0.050656      0.028909      0.099261      0.064414   \n",
       "std        0.477074      0.219295      0.167552      0.299014      0.245491   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           sb_outln      sb_admis      sb_other      explnstp       othpers  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.012090      0.010973      0.106913      0.998714      0.277689   \n",
       "std        0.109289      0.104176      0.309005      0.035831      0.447862   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "           sumissue        perobs       perstop         CPI_F         CPI_H  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.027608      2.599590      7.876697    243.872676    235.478761   \n",
       "std        0.163849      7.016901      7.574259      3.512057      4.565384   \n",
       "min        0.000000      0.000000      0.000000    237.820000    228.892000   \n",
       "25%        0.000000      1.000000      5.000000    240.226000    231.689000   \n",
       "50%        0.000000      1.000000      5.000000    244.902000    234.675000   \n",
       "75%        0.000000      2.000000     10.000000    247.196000    239.298000   \n",
       "max        1.000000    935.000000    180.000000    248.575000    246.271000   \n",
       "\n",
       "              CPI_C         CPI_T         CPI_M    crimsusp_3    crimsusp_4  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean     126.929066    207.052416    441.771970      0.022910      0.039775   \n",
       "std        2.596709     10.639750     10.961925      0.149617      0.195431   \n",
       "min      121.878000    187.345000    427.089000      0.000000      0.000000   \n",
       "25%      124.547000    197.145000    433.369000      0.000000      0.000000   \n",
       "50%      127.083000    208.012000    438.445000      0.000000      0.000000   \n",
       "75%      128.963000    214.673000    447.213000      0.000000      0.000000   \n",
       "max      131.961000    223.392000    469.333000      1.000000      1.000000   \n",
       "\n",
       "         crimsusp_6    crimsusp_8    crimsusp_9   crimsusp_10   crimsusp_11  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.000429      0.008142      0.000275      0.014309      0.001500   \n",
       "std        0.020696      0.089864      0.016595      0.118763      0.038698   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        crimsusp_12   crimsusp_13   crimsusp_14   crimsusp_16   crimsusp_17  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.112682      0.006152      0.001025      0.390049      0.000627   \n",
       "std        0.316206      0.078195      0.032005      0.487765      0.025041   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        crimsusp_18   crimsusp_20   crimsusp_21   crimsusp_22   crimsusp_23  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.000245      0.000367      0.032123      0.002127      0.000184   \n",
       "std        0.015646      0.019162      0.176328      0.046073      0.013550   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        crimsusp_24   crimsusp_28   crimsusp_29   crimsusp_31   crimsusp_32  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.000153      0.028878      0.000275      0.000995      0.191206   \n",
       "std        0.012370      0.167466      0.016595      0.031524      0.393254   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        crimsusp_33   crimsusp_34   crimsusp_36   crimsusp_37   crimsusp_38  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.000275      0.059272      0.000184      0.000444      0.000857   \n",
       "std        0.016595      0.236135      0.013550      0.021062      0.029263   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        crimsusp_39   crimsusp_43   crimsusp_49   crimsusp_50   crimsusp_53  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.058400      0.000153      0.001010      0.023063      0.000566   \n",
       "std        0.234499      0.012370      0.031766      0.150105      0.023789   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          addrpct_1     addrpct_5     addrpct_6     addrpct_7     addrpct_9  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.002556      0.006550      0.002005      0.007453      0.012014   \n",
       "std        0.050490      0.080668      0.044730      0.086009      0.108947   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_10    addrpct_13    addrpct_14    addrpct_17    addrpct_18  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.004285      0.011340      0.012733      0.004117      0.004377   \n",
       "std        0.065321      0.105885      0.112120      0.064030      0.066014   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_19    addrpct_20    addrpct_22    addrpct_23    addrpct_24  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.008509      0.005724      0.001867      0.017064      0.007040   \n",
       "std        0.091851      0.075439      0.043170      0.129510      0.083608   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_25    addrpct_26    addrpct_28   addrpct_30    addrpct_32  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.00000  65343.000000   \n",
       "mean       0.017569      0.004423      0.006826      0.00531      0.012014   \n",
       "std        0.131379      0.066358      0.082335      0.07268      0.108947   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.00000      1.000000   \n",
       "\n",
       "         addrpct_33    addrpct_34    addrpct_40    addrpct_41    addrpct_42  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.005601      0.008356      0.026782      0.020737      0.011876   \n",
       "std        0.074632      0.091029      0.161446      0.142503      0.108328   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_43    addrpct_44    addrpct_45    addrpct_46    addrpct_47  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.014722      0.022849      0.008448      0.008264      0.014049   \n",
       "std        0.120440      0.149422      0.091523      0.090531      0.117694   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_48    addrpct_49    addrpct_50    addrpct_52    addrpct_60  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.004010      0.021563      0.007300      0.012075      0.018717   \n",
       "std        0.063195      0.145253      0.085128      0.109221      0.135523   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_61    addrpct_62    addrpct_63    addrpct_66    addrpct_67  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.005418      0.013284      0.006458      0.020262      0.029230   \n",
       "std        0.073405      0.114488      0.080104      0.140897      0.168453   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_68    addrpct_69    addrpct_70    addrpct_71    addrpct_72  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.003535      0.009902      0.016161      0.012121      0.006045   \n",
       "std        0.059353      0.099014      0.126095      0.109425      0.077515   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_73    addrpct_75    addrpct_76    addrpct_77    addrpct_78  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.017324      0.021257      0.009978      0.007621      0.004346   \n",
       "std        0.130476      0.144241      0.099392      0.086968      0.065784   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_79    addrpct_81    addrpct_83    addrpct_84    addrpct_88  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.025481      0.006504      0.011401      0.016299      0.006382   \n",
       "std        0.157582      0.080386      0.106168      0.126622      0.079631   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         addrpct_90    addrpct_94   addrpct_100   addrpct_101   addrpct_102  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.014845      0.003566      0.005494      0.019727      0.025404   \n",
       "std        0.120932      0.059608      0.073919      0.139061      0.157351   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        addrpct_103   addrpct_104   addrpct_105   addrpct_106   addrpct_107  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.007223      0.008126      0.030516      0.063802      0.024012   \n",
       "std        0.084684      0.089780      0.172003      0.244401      0.153087   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        addrpct_108   addrpct_109   addrpct_110   addrpct_111   addrpct_112  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.003948      0.015977      0.007331      0.010498      0.011417   \n",
       "std        0.062713      0.125388      0.085305      0.101923      0.106238   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        addrpct_113   addrpct_114   addrpct_115   addrpct_120   addrpct_121  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.012197      0.027470      0.006474      0.036806      0.031511   \n",
       "std        0.109766      0.163451      0.080198      0.188286      0.174695   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        addrpct_122   addrpct_123         sex_F         sex_M        race_A  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.018931      0.006596      0.064950      0.935050      0.053196   \n",
       "std        0.136282      0.080948      0.246439      0.246439      0.224426   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             race_B        race_I        race_P        race_Q        race_W  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.529621      0.003811      0.063863      0.223834      0.115973   \n",
       "std        0.499126      0.061613      0.244511      0.416815      0.320195   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             race_Z   haircolr_BA   haircolr_BK   haircolr_BL   haircolr_BR  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.009703      0.024104      0.736207      0.013161      0.206663   \n",
       "std        0.098024      0.153372      0.440692      0.113966      0.404915   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        haircolr_DY   haircolr_GY   haircolr_RA   haircolr_SP   haircolr_ZZ  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.000321      0.008402      0.002219      0.005708      0.003214   \n",
       "std        0.017924      0.091276      0.047055      0.075338      0.056600   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        eyecolor_BK   eyecolor_BL   eyecolor_BR   eyecolor_DF   eyecolor_GR  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.065133      0.018946      0.895459      0.000291      0.007881   \n",
       "std        0.246763      0.136336      0.305963      0.017050      0.088428   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        eyecolor_GY   eyecolor_HA    eyecolor_Z       build_H       build_M  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.001087      0.009060      0.002143      0.088441      0.518877   \n",
       "std        0.032946      0.094752      0.046238      0.283937      0.499647   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            build_T       build_U    typeofid_O    typeofid_P    typeofid_R  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.385183      0.007499      0.018579      0.586872      0.022237   \n",
       "std        0.486642      0.086271      0.135033      0.492399      0.147453   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      1.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "         typeofid_V      timestop     timestop2     timestop3           CPI  \\\n",
       "count  65343.000000  65343.000000  65343.000000  65343.000000  65343.000000   \n",
       "mean       0.372312     14.057254    257.761544    257.761544    236.678826   \n",
       "std        0.483425      7.756036    189.062376    189.062376      2.117683   \n",
       "min        0.000000      0.000000      0.000000      0.000000    233.049000   \n",
       "25%        0.000000      8.050000     64.802500     64.802500    234.781000   \n",
       "50%        0.000000     16.200000    262.440000    262.440000    237.072000   \n",
       "75%        1.000000     20.750000    430.562500    430.562500    237.945000   \n",
       "max        1.000000     23.983333    575.200278    575.200278    241.729000   \n",
       "\n",
       "               CPI2         SP500           sp2  crimsusp_other  \n",
       "count  65343.000000  65343.000000  6.534300e+04    65343.000000  \n",
       "mean   56021.351326   1979.688236  3.931457e+06        0.001347  \n",
       "std     1003.064109    110.868007  4.394685e+05        0.036674  \n",
       "min    54311.836401   1817.034737  3.301615e+06        0.000000  \n",
       "25%    55122.117961   1864.263333  3.475478e+06        0.000000  \n",
       "50%    56203.133184   1947.087619  3.791150e+06        0.000000  \n",
       "75%    56617.823025   2080.616500  4.328965e+06        0.000000  \n",
       "max    58432.909441   2246.629048  5.047342e+06        1.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (np.shape(dataClean))\n",
    "dataClean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read feature-label data direcly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataClean.to_csv(r\".\\DTT.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split\n",
    "## never use test set for model selction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## balance data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54230 11113\n"
     ]
    }
   ],
   "source": [
    "data0 = dataClean.loc[dataClean['arstmade']==0]\n",
    "data1 = dataClean.loc[dataClean['arstmade']==1]\n",
    "print (len(data0), len(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use stratified split to avoid structure change in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13557 40673\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arstmade</th>\n",
       "      <th>inout</th>\n",
       "      <th>offunif</th>\n",
       "      <th>frisked</th>\n",
       "      <th>searched</th>\n",
       "      <th>contrabn</th>\n",
       "      <th>pistol</th>\n",
       "      <th>riflshot</th>\n",
       "      <th>asltweap</th>\n",
       "      <th>knifcuti</th>\n",
       "      <th>othrweap</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>ht</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>radio</th>\n",
       "      <th>ac_rept</th>\n",
       "      <th>ac_inves</th>\n",
       "      <th>rf_vcrim</th>\n",
       "      <th>rf_othsw</th>\n",
       "      <th>ac_proxm</th>\n",
       "      <th>rf_attir</th>\n",
       "      <th>cs_objcs</th>\n",
       "      <th>cs_descr</th>\n",
       "      <th>cs_casng</th>\n",
       "      <th>cs_lkout</th>\n",
       "      <th>rf_vcact</th>\n",
       "      <th>cs_cloth</th>\n",
       "      <th>cs_drgtr</th>\n",
       "      <th>ac_evasv</th>\n",
       "      <th>ac_assoc</th>\n",
       "      <th>cs_furtv</th>\n",
       "      <th>rf_rfcmp</th>\n",
       "      <th>ac_cgdir</th>\n",
       "      <th>rf_verbl</th>\n",
       "      <th>cs_vcrim</th>\n",
       "      <th>cs_bulge</th>\n",
       "      <th>cs_other</th>\n",
       "      <th>ac_incid</th>\n",
       "      <th>ac_time</th>\n",
       "      <th>rf_knowl</th>\n",
       "      <th>ac_stsnd</th>\n",
       "      <th>ac_other</th>\n",
       "      <th>sb_hdobj</th>\n",
       "      <th>sb_outln</th>\n",
       "      <th>sb_admis</th>\n",
       "      <th>sb_other</th>\n",
       "      <th>explnstp</th>\n",
       "      <th>othpers</th>\n",
       "      <th>sumissue</th>\n",
       "      <th>perobs</th>\n",
       "      <th>perstop</th>\n",
       "      <th>CPI_F</th>\n",
       "      <th>CPI_H</th>\n",
       "      <th>CPI_C</th>\n",
       "      <th>CPI_T</th>\n",
       "      <th>CPI_M</th>\n",
       "      <th>crimsusp_3</th>\n",
       "      <th>crimsusp_4</th>\n",
       "      <th>crimsusp_6</th>\n",
       "      <th>crimsusp_8</th>\n",
       "      <th>crimsusp_9</th>\n",
       "      <th>crimsusp_10</th>\n",
       "      <th>crimsusp_11</th>\n",
       "      <th>crimsusp_12</th>\n",
       "      <th>crimsusp_13</th>\n",
       "      <th>crimsusp_14</th>\n",
       "      <th>crimsusp_16</th>\n",
       "      <th>crimsusp_17</th>\n",
       "      <th>crimsusp_18</th>\n",
       "      <th>crimsusp_20</th>\n",
       "      <th>crimsusp_21</th>\n",
       "      <th>crimsusp_22</th>\n",
       "      <th>crimsusp_23</th>\n",
       "      <th>crimsusp_24</th>\n",
       "      <th>crimsusp_28</th>\n",
       "      <th>crimsusp_29</th>\n",
       "      <th>crimsusp_31</th>\n",
       "      <th>crimsusp_32</th>\n",
       "      <th>crimsusp_33</th>\n",
       "      <th>crimsusp_34</th>\n",
       "      <th>crimsusp_36</th>\n",
       "      <th>crimsusp_37</th>\n",
       "      <th>crimsusp_38</th>\n",
       "      <th>crimsusp_39</th>\n",
       "      <th>crimsusp_43</th>\n",
       "      <th>crimsusp_49</th>\n",
       "      <th>crimsusp_50</th>\n",
       "      <th>crimsusp_53</th>\n",
       "      <th>addrpct_1</th>\n",
       "      <th>addrpct_5</th>\n",
       "      <th>addrpct_6</th>\n",
       "      <th>addrpct_7</th>\n",
       "      <th>addrpct_9</th>\n",
       "      <th>addrpct_10</th>\n",
       "      <th>addrpct_13</th>\n",
       "      <th>addrpct_14</th>\n",
       "      <th>addrpct_17</th>\n",
       "      <th>addrpct_18</th>\n",
       "      <th>addrpct_19</th>\n",
       "      <th>addrpct_20</th>\n",
       "      <th>addrpct_22</th>\n",
       "      <th>addrpct_23</th>\n",
       "      <th>addrpct_24</th>\n",
       "      <th>addrpct_25</th>\n",
       "      <th>addrpct_26</th>\n",
       "      <th>addrpct_28</th>\n",
       "      <th>addrpct_30</th>\n",
       "      <th>addrpct_32</th>\n",
       "      <th>addrpct_33</th>\n",
       "      <th>addrpct_34</th>\n",
       "      <th>addrpct_40</th>\n",
       "      <th>addrpct_41</th>\n",
       "      <th>addrpct_42</th>\n",
       "      <th>addrpct_43</th>\n",
       "      <th>addrpct_44</th>\n",
       "      <th>addrpct_45</th>\n",
       "      <th>addrpct_46</th>\n",
       "      <th>addrpct_47</th>\n",
       "      <th>addrpct_48</th>\n",
       "      <th>addrpct_49</th>\n",
       "      <th>addrpct_50</th>\n",
       "      <th>addrpct_52</th>\n",
       "      <th>addrpct_60</th>\n",
       "      <th>addrpct_61</th>\n",
       "      <th>addrpct_62</th>\n",
       "      <th>addrpct_63</th>\n",
       "      <th>addrpct_66</th>\n",
       "      <th>addrpct_67</th>\n",
       "      <th>addrpct_68</th>\n",
       "      <th>addrpct_69</th>\n",
       "      <th>addrpct_70</th>\n",
       "      <th>addrpct_71</th>\n",
       "      <th>addrpct_72</th>\n",
       "      <th>addrpct_73</th>\n",
       "      <th>addrpct_75</th>\n",
       "      <th>addrpct_76</th>\n",
       "      <th>addrpct_77</th>\n",
       "      <th>addrpct_78</th>\n",
       "      <th>addrpct_79</th>\n",
       "      <th>addrpct_81</th>\n",
       "      <th>addrpct_83</th>\n",
       "      <th>addrpct_84</th>\n",
       "      <th>addrpct_88</th>\n",
       "      <th>addrpct_90</th>\n",
       "      <th>addrpct_94</th>\n",
       "      <th>addrpct_100</th>\n",
       "      <th>addrpct_101</th>\n",
       "      <th>addrpct_102</th>\n",
       "      <th>addrpct_103</th>\n",
       "      <th>addrpct_104</th>\n",
       "      <th>addrpct_105</th>\n",
       "      <th>addrpct_106</th>\n",
       "      <th>addrpct_107</th>\n",
       "      <th>addrpct_108</th>\n",
       "      <th>addrpct_109</th>\n",
       "      <th>addrpct_110</th>\n",
       "      <th>addrpct_111</th>\n",
       "      <th>addrpct_112</th>\n",
       "      <th>addrpct_113</th>\n",
       "      <th>addrpct_114</th>\n",
       "      <th>addrpct_115</th>\n",
       "      <th>addrpct_120</th>\n",
       "      <th>addrpct_121</th>\n",
       "      <th>addrpct_122</th>\n",
       "      <th>addrpct_123</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>race_A</th>\n",
       "      <th>race_B</th>\n",
       "      <th>race_I</th>\n",
       "      <th>race_P</th>\n",
       "      <th>race_Q</th>\n",
       "      <th>race_W</th>\n",
       "      <th>race_Z</th>\n",
       "      <th>haircolr_BA</th>\n",
       "      <th>haircolr_BK</th>\n",
       "      <th>haircolr_BL</th>\n",
       "      <th>haircolr_BR</th>\n",
       "      <th>haircolr_DY</th>\n",
       "      <th>haircolr_GY</th>\n",
       "      <th>haircolr_RA</th>\n",
       "      <th>haircolr_SP</th>\n",
       "      <th>haircolr_ZZ</th>\n",
       "      <th>eyecolor_BK</th>\n",
       "      <th>eyecolor_BL</th>\n",
       "      <th>eyecolor_BR</th>\n",
       "      <th>eyecolor_DF</th>\n",
       "      <th>eyecolor_GR</th>\n",
       "      <th>eyecolor_GY</th>\n",
       "      <th>eyecolor_HA</th>\n",
       "      <th>eyecolor_Z</th>\n",
       "      <th>build_H</th>\n",
       "      <th>build_M</th>\n",
       "      <th>build_T</th>\n",
       "      <th>build_U</th>\n",
       "      <th>typeofid_O</th>\n",
       "      <th>typeofid_P</th>\n",
       "      <th>typeofid_R</th>\n",
       "      <th>typeofid_V</th>\n",
       "      <th>timestop</th>\n",
       "      <th>timestop2</th>\n",
       "      <th>timestop3</th>\n",
       "      <th>CPI</th>\n",
       "      <th>CPI2</th>\n",
       "      <th>SP500</th>\n",
       "      <th>sp2</th>\n",
       "      <th>crimsusp_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.086282</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>0.016019</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.004091</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.002374</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.003731</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.027710</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.031113</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.065201</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>5.440725e-09</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>3.536471e-08</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>6.338445e-07</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.003150</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>7.193101</td>\n",
       "      <td>0.513435</td>\n",
       "      <td>2067.182308</td>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.006073</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.071498</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.014793</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.005205</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>2.604261</td>\n",
       "      <td>0.156513</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.021712</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.045569</td>\n",
       "      <td>0.049348</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.008810</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.007438</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>5.598994e-07</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>1.426426e-06</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.006118</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000890</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.006226</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>5.950012e-06</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.001577</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.005523</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.006122</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.004306</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.167023</td>\n",
       "      <td>0.167023</td>\n",
       "      <td>0.012564</td>\n",
       "      <td>6.058596</td>\n",
       "      <td>0.166330</td>\n",
       "      <td>748.312500</td>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arstmade     inout   offunif   frisked  searched  contrabn    pistol  \\\n",
       "mean       0.0  0.003240  0.005958  0.000290  0.000310  0.000829  0.000258   \n",
       "std        0.0  0.003172  0.000596  0.000102  0.000425  0.003963  0.003618   \n",
       "\n",
       "      riflshot  asltweap  knifcuti  othrweap       age    weight        ht  \\\n",
       "mean  0.000037       0.0  0.000055  0.000535  0.086282  0.019842  0.016019   \n",
       "std   0.006073       0.0  0.000258  0.004039  0.071498  0.026573  0.004457   \n",
       "\n",
       "          year     month     radio   ac_rept  ac_inves  rf_vcrim  rf_othsw  \\\n",
       "mean  0.002827  0.029204  0.004091  0.002499  0.005011  0.002922  0.003158   \n",
       "std   0.002193  0.014793  0.000676  0.001469  0.005205  0.001818  0.003842   \n",
       "\n",
       "      ac_proxm  rf_attir  cs_objcs  cs_descr  cs_casng  cs_lkout  rf_vcact  \\\n",
       "mean  0.000689  0.002358  0.000681  0.004328  0.004361  0.002374  0.001829   \n",
       "std   0.000247  0.003825  0.001962  0.001449  0.002467  0.002605  0.002766   \n",
       "\n",
       "      cs_cloth  cs_drgtr  ac_evasv  ac_assoc  cs_furtv  rf_rfcmp  ac_cgdir  \\\n",
       "mean  0.002030  0.001731  0.001874  0.002763  0.003731  0.001498  0.002998   \n",
       "std   0.004222  0.003279  0.001505  0.004540  0.001354  0.001769  0.001991   \n",
       "\n",
       "      rf_verbl  cs_vcrim  cs_bulge  cs_other  ac_incid   ac_time  rf_knowl  \\\n",
       "mean  0.000700  0.000299  0.001312  0.002164  0.000423  0.003214  0.000219   \n",
       "std   0.003613  0.000414  0.002124  0.000822  0.000029  0.000986  0.000431   \n",
       "\n",
       "      ac_stsnd  ac_other  sb_hdobj  sb_outln  sb_admis  sb_other  explnstp  \\\n",
       "mean  0.000259  0.002585  0.002137  0.000701  0.000018  0.000628  0.000092   \n",
       "std   0.000725  0.003479  0.004179  0.004186  0.000138  0.001635  0.001572   \n",
       "\n",
       "       othpers  sumissue    perobs   perstop     CPI_F     CPI_H     CPI_C  \\\n",
       "mean  0.001298  0.001052  0.011013  0.027710  0.012410  0.031113  0.004538   \n",
       "std   0.000581  0.002821  2.604261  0.156513  0.006131  0.021712  0.002720   \n",
       "\n",
       "         CPI_T     CPI_M  crimsusp_3  crimsusp_4  crimsusp_6  crimsusp_8  \\\n",
       "mean  0.021656  0.065201    0.000645    0.002672    0.000111    0.000442   \n",
       "std   0.045569  0.049348    0.002028    0.006020    0.003341    0.002584   \n",
       "\n",
       "      crimsusp_9  crimsusp_10  crimsusp_11  crimsusp_12  crimsusp_13  \\\n",
       "mean    0.000203     0.000019     0.000461     0.007657     0.001162   \n",
       "std     0.005552     0.000089     0.005879     0.008810     0.007555   \n",
       "\n",
       "      crimsusp_14  crimsusp_16  crimsusp_17  crimsusp_18  crimsusp_20  \\\n",
       "mean     0.000350     0.000974     0.000018     0.000055     0.000018   \n",
       "std      0.005168     0.000178     0.000487     0.007438     0.000444   \n",
       "\n",
       "      crimsusp_21  crimsusp_22  crimsusp_23   crimsusp_24  crimsusp_28  \\\n",
       "mean     0.000038     0.000019     0.000074  5.440725e-09     0.000294   \n",
       "std      0.000101     0.000212     0.003556  5.598994e-07     0.000805   \n",
       "\n",
       "      crimsusp_29   crimsusp_31  crimsusp_32  crimsusp_33  crimsusp_34  \\\n",
       "mean     0.000111  3.536471e-08     0.002594     0.000111     0.000422   \n",
       "std      0.003136  1.426426e-06     0.002402     0.003341     0.000808   \n",
       "\n",
       "      crimsusp_36  crimsusp_37  crimsusp_38  crimsusp_39  crimsusp_43  \\\n",
       "mean     0.000111     0.000295     0.000240     0.000662     0.000018   \n",
       "std      0.004990     0.006118     0.003683     0.001193     0.000785   \n",
       "\n",
       "      crimsusp_49  crimsusp_50  crimsusp_53  addrpct_1  addrpct_5  addrpct_6  \\\n",
       "mean     0.000129     0.001493     0.000111   0.000572   0.000461   0.000184   \n",
       "std      0.002390     0.006347     0.002818   0.005791   0.002823   0.001998   \n",
       "\n",
       "      addrpct_7  addrpct_9  addrpct_10  addrpct_13  addrpct_14  addrpct_17  \\\n",
       "mean   0.000037   0.000074    0.000387    0.000222    0.001623    0.000037   \n",
       "std    0.000217   0.000408    0.003088    0.001172    0.006850    0.000289   \n",
       "\n",
       "      addrpct_18  addrpct_19  addrpct_20  addrpct_22  addrpct_23  addrpct_24  \\\n",
       "mean    0.000129    0.000148    0.000480    0.000203    0.000388    0.000129   \n",
       "std     0.000935    0.000890    0.003083    0.002165    0.001494    0.000795   \n",
       "\n",
       "      addrpct_25  addrpct_26  addrpct_28  addrpct_30  addrpct_32  addrpct_33  \\\n",
       "mean    0.000147    0.000719    0.000056    0.000535    0.000922    0.000775   \n",
       "std     0.000618    0.006226    0.000333    0.003700    0.004596    0.004887   \n",
       "\n",
       "      addrpct_34  addrpct_40  addrpct_41  addrpct_42  addrpct_43  addrpct_44  \\\n",
       "mean    0.000461    0.000405    0.000536    0.000682    0.000756    0.001458   \n",
       "std     0.002596    0.001757    0.001725    0.004176    0.003541    0.004518   \n",
       "\n",
       "      addrpct_45  addrpct_46  addrpct_47  addrpct_48  addrpct_49  addrpct_50  \\\n",
       "mean    0.000922    0.000313    0.000037    0.000351    0.001216    0.000756   \n",
       "std     0.005001    0.001698    0.000177    0.002799    0.004018    0.004240   \n",
       "\n",
       "      addrpct_52    addrpct_60  addrpct_61  addrpct_62  addrpct_63  \\\n",
       "mean    0.000903  6.338445e-07    0.000295    0.001162    0.000793   \n",
       "std     0.003905  5.950012e-06    0.001984    0.004706    0.004726   \n",
       "\n",
       "      addrpct_66  addrpct_67  addrpct_68  addrpct_69  addrpct_70  addrpct_71  \\\n",
       "mean    0.000073    0.002212    0.000019     0.00048    0.000111    0.000368   \n",
       "std     0.000244    0.005891    0.000157     0.00224    0.000404    0.001613   \n",
       "\n",
       "      addrpct_72  addrpct_73  addrpct_75  addrpct_76  addrpct_77  addrpct_78  \\\n",
       "mean    0.000369    0.000277    0.001015    0.000572    0.000516    0.000037   \n",
       "std     0.002399    0.001015    0.003325    0.002752    0.002947    0.000265   \n",
       "\n",
       "      addrpct_79  addrpct_81  addrpct_83  addrpct_84  addrpct_88  addrpct_90  \\\n",
       "mean    0.000536    0.000239    0.000941    0.001550    0.000369    0.000037   \n",
       "std     0.001577    0.001482    0.004348    0.005523    0.002297    0.000151   \n",
       "\n",
       "      addrpct_94  addrpct_100  addrpct_101  addrpct_102  addrpct_103  \\\n",
       "mean    0.000424     0.000904     0.000462     0.000683     0.000701   \n",
       "std     0.003404     0.005805     0.001510     0.001983     0.003879   \n",
       "\n",
       "      addrpct_104  addrpct_105  addrpct_106  addrpct_107  addrpct_108  \\\n",
       "mean     0.000166     0.001529     0.000869     0.000296     0.000313   \n",
       "std      0.000937     0.004178     0.001460     0.000880     0.002397   \n",
       "\n",
       "      addrpct_109  addrpct_110  addrpct_111  addrpct_112  addrpct_113  \\\n",
       "mean     0.001419     0.000258     0.001365     0.001438     0.000073   \n",
       "std      0.005450     0.001636     0.006122     0.006423     0.000310   \n",
       "\n",
       "      addrpct_114  addrpct_115  addrpct_120  addrpct_121  addrpct_122  \\\n",
       "mean     0.000589     0.000184     0.000884     0.001326     0.001310   \n",
       "std      0.001661     0.001169     0.002040     0.003330     0.004306   \n",
       "\n",
       "      addrpct_123     sex_F     sex_M    race_A    race_B    race_I    race_P  \\\n",
       "mean     0.000442  0.000403  0.000403  0.001750  0.001013  0.000608  0.000256   \n",
       "std      0.002871  0.000742  0.000742  0.003368  0.000085  0.004880  0.000468   \n",
       "\n",
       "        race_Q    race_W    race_Z  haircolr_BA  haircolr_BK  haircolr_BL  \\\n",
       "mean  0.004839  0.001913  0.000701     0.000111     0.004084     0.001365   \n",
       "std   0.003336  0.002245  0.003528     0.000369     0.002223     0.005831   \n",
       "\n",
       "      haircolr_BR  haircolr_DY  haircolr_GY  haircolr_RA  haircolr_SP  \\\n",
       "mean     0.004897     0.000184     0.000534     0.000258     0.000055   \n",
       "std      0.003523     0.007477     0.002990     0.002822     0.000416   \n",
       "\n",
       "      haircolr_ZZ  eyecolor_BK  eyecolor_BL  eyecolor_BR  eyecolor_DF  \\\n",
       "mean     0.000147     0.003114     0.000553     0.002873     0.000074   \n",
       "std      0.001286     0.005603     0.001984     0.003807     0.002300   \n",
       "\n",
       "      eyecolor_GR  eyecolor_GY  eyecolor_HA  eyecolor_Z   build_H   build_M  \\\n",
       "mean     0.000314     0.000018     0.000314    0.000258  0.000796  0.000775   \n",
       "std      0.001766     0.000294     0.001740    0.002562  0.001169  0.000028   \n",
       "\n",
       "       build_T   build_U  typeofid_O  typeofid_P  typeofid_R  typeofid_V  \\\n",
       "mean  0.001129  0.000442    0.000977    0.003949    0.000091    0.002881   \n",
       "std   0.000271  0.002598    0.003722    0.000605    0.000270    0.000695   \n",
       "\n",
       "      timestop  timestop2  timestop3       CPI      CPI2     SP500  \\\n",
       "mean  0.003150   0.030000   0.030000  0.015087  7.193101  0.513435   \n",
       "std   0.007395   0.167023   0.167023  0.012564  6.058596  0.166330   \n",
       "\n",
       "              sp2  crimsusp_other  \n",
       "mean  2067.182308        0.000443  \n",
       "std    748.312500        0.005626  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.75, random_state=0)\n",
    "data0Y = data0[['arstmade']]\n",
    "data0X = data0.drop('arstmade', 1)\n",
    "\n",
    "for idx1, idx2 in sss.split(data0X, data0Y):\n",
    "    print (len(idx1), len(idx2))\n",
    "\n",
    "data0_used = data0.iloc[idx1, :]\n",
    "\n",
    "#check whether structure change\n",
    "abs(data0.describe().loc[['mean', 'std'], :] - data0_used.describe().loc[['mean', 'std'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data used to train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_used = pd.concat([data0_used, data1], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the data_used directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24670"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_used.to_csv(r\".\\data_used.csv\")\n",
    "len(data_used)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standardize the train_all, fit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "def CV(data, clf, nfold=5):\n",
    "    X = data.drop(['arstmade'], 1)\n",
    "    y = data['arstmade']    \n",
    "    \n",
    "    #store train, test scores\n",
    "    scorings = ['recall', 'precision', 'accuracy', 'f1', 'roc_auc']\n",
    "    keys = [t+'_'+sc for sc in scorings for t in ['train', 'test']]\n",
    "    scores = {k: np.zeros(nfold) for k in keys}\n",
    "    \n",
    "    #store test details\n",
    "    dtls = ['coef', 'interc', 'label', 'pred', 'pred_prob']\n",
    "    details = {k:[] for k in dtls}\n",
    "    \n",
    "    #stratified Kfold, K=5 default\n",
    "    skf = StratifiedKFold(n_splits=nfold, random_state=0, shuffle=True)\n",
    "    for i, (tr_idx, te_idx) in enumerate(skf.split(X, y)):\n",
    "        print (i, len(tr_idx), len(te_idx))\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "        details['label'].append(y_te)\n",
    "        \n",
    "        #stdize the train set\n",
    "        Xtr_sc = X_tr.loc[:, X_tr.max(0) > 1]\n",
    "        scaler = StandardScaler().fit(Xtr_sc)\n",
    "        Xtr_ = scaler.transform(Xtr_sc)\n",
    "        Xtr_sc = pd.DataFrame(data=Xtr_, index=Xtr_sc.index, columns=Xtr_sc.columns)\n",
    "        X_tr.loc[:, X_tr.max(0) > 1] = Xtr_sc\n",
    "        \n",
    "        #fit the model\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        try:\n",
    "            details['coef'].append(clf.coef_)\n",
    "            details['interc'].append(clf.intercept_)\n",
    "        except:\n",
    "            print (\"no coef, intercept in nonlinear kernel\")\n",
    "        \n",
    "        #get train score\n",
    "        acc = clf.score(X_tr, y_tr)\n",
    "        scores['train_accuracy'][i] = acc\n",
    "        \n",
    "        y_tr_pred = clf.predict(X_tr)\n",
    "        y_tr_pred_prob = clf.predict_proba(X_tr)\n",
    "        \n",
    "        rec = recall_score(y_tr, y_tr_pred)\n",
    "        scores['train_recall'][i] = rec\n",
    "        \n",
    "        pre = precision_score(y_tr, y_tr_pred)\n",
    "        scores['train_precision'][i] = pre\n",
    "        \n",
    "        f1 = f1_score(y_tr, y_tr_pred)\n",
    "        scores['train_f1'][i] = f1\n",
    "        \n",
    "        auc = roc_auc_score(y_tr, y_tr_pred_prob[:, 1])\n",
    "        scores['train_roc_auc'][i] = auc\n",
    "        \n",
    "        #pred the test\n",
    "        Xte_sc = X_te.loc[:, X_tr.max(0) > 1]\n",
    "        Xte_ = scaler.transform(Xte_sc)\n",
    "        Xte_sc = pd.DataFrame(data=Xte_, index=Xte_sc.index, columns=Xte_sc.columns)\n",
    "        X_te.loc[:, X_te.max(0) > 1] = Xte_sc\n",
    "        \n",
    "        y_te_pred = clf.predict(X_te)\n",
    "        y_te_pred_prob = clf.predict_proba(X_te)\n",
    "        \n",
    "        details['pred'].append(y_te_pred)\n",
    "        details['pred_prob'].append(y_te_pred_prob)\n",
    "        \n",
    "        #get test score\n",
    "        acc = clf.score(X_te, y_te)\n",
    "        scores['test_accuracy'][i] = acc\n",
    "        \n",
    "        y_te_pred = clf.predict(X_te)\n",
    "        y_te_pred_prob = clf.predict_proba(X_te)\n",
    "        \n",
    "        rec = recall_score(y_te, y_te_pred)\n",
    "        scores['test_recall'][i] = rec\n",
    "        \n",
    "        pre = precision_score(y_te, y_te_pred)\n",
    "        scores['test_precision'][i] = pre\n",
    "        \n",
    "        f1 = f1_score(y_te, y_te_pred)\n",
    "        scores['test_f1'][i] = f1\n",
    "        \n",
    "        auc = roc_auc_score(y_te, y_te_pred_prob[:, 1])\n",
    "        scores['test_roc_auc'][i] = auc\n",
    "        \n",
    "    return details, scores, pd.DataFrame(scores)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no k folds to observe fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "def splitData(data):\n",
    "    X = data.drop(['arstmade'], 1)\n",
    "    y = data['arstmade']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "    print (np.shape(X_train), np.shape(y_train), np.shape(X_test), np.shape(y_test))\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def trainModel(Xtr, ytr, clf):\n",
    "    Xtr_sc = Xtr.loc[:, Xtr.max(0) > 1]\n",
    "    scaler = StandardScaler().fit(Xtr_sc)\n",
    "    Xtr_ = scaler.transform(Xtr_sc)\n",
    "    Xtr_sc = pd.DataFrame(data=Xtr_, index=Xtr_sc.index, columns=Xtr_sc.columns)\n",
    "    Xtr.loc[:, Xtr.max(0) > 1] = Xtr_sc\n",
    "    #print (Xtr.mean())\n",
    "    \n",
    "    clf.fit(Xtr, ytr)\n",
    "    print (\"train score = %.5f\" % (clf.score(Xtr, ytr)))\n",
    "    return scaler, clf\n",
    "\n",
    "def fairness_on_test(Xte, yte, scaler, clf):\n",
    "    print (clf.score(Xte, yte))\n",
    "    Xte_sc = Xte.loc[:, Xte.max(0) > 1]\n",
    "    Xte_ = scaler.transform(Xte_sc)\n",
    "    Xte_sc = pd.DataFrame(data=Xte_, index=Xte_sc.index, columns=Xte_sc.columns)\n",
    "    Xte.loc[:, Xte.max(0) > 1] = Xte_sc\n",
    "    #print (Xte.mean())\n",
    "    \n",
    "    y_pred = clf.predict(Xte)\n",
    "    #print (clf.score(Xte, yte))\n",
    "    Xte['y_true'] = yte\n",
    "    Xte['y_pred'] = y_pred\n",
    "    return Xte\n",
    "\n",
    "def get_fair_coef(X_train, clf):\n",
    "    fair_col = [c for c in X_train.columns if c.startswith('race') or c.startswith('sex')]\n",
    "    fair_coef = pd.DataFrame(data=clf.coef_[0], index=X_train.columns).loc[fair_col]\n",
    "    return fair_coef\n",
    "\n",
    "def FPR(pred, X_train):\n",
    "    fair_col = [c for c in X_train.columns if c.startswith('race') or c.startswith('sex')]\n",
    "    pred_fair = pred.loc[:, fair_col+['y_true', 'y_pred']]\n",
    "    \n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    for col in fair_col[:]:\n",
    "        data = pred_fair.loc[:, [col, 'y_true', 'y_pred']]\n",
    "        data = data.loc[data[col]==1]\n",
    "        tn, fp, fn, tp = confusion_matrix(data['y_true'], data['y_pred']).ravel()\n",
    "        #print (tn, fp, fn, tp)\n",
    "        fpr = fp/(fp+tn)\n",
    "        tpr = tp/(tp+fn)\n",
    "        fprs.append(fpr)\n",
    "        tprs.append(tpr)\n",
    "    \n",
    "    return pd.DataFrame(data=fprs, index=fair_col), pd.DataFrame(data=tprs, index=fair_col)         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A\tASIAN/PACIFIC ISLANDER\n",
    "B\tBLACK\n",
    "I\tAMERICAN INDIAN/ALASKAN NATIVE\n",
    "P\tBLACK-HISPANIC\n",
    "Q\tWHITE-HISPANIC\n",
    "W\tWHITE\n",
    "X\tUNKNOWN\n",
    "Z\tOTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use unblanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 52274 13069\n",
      "1 52274 13069\n",
      "2 52274 13069\n",
      "3 52275 13068\n",
      "4 52275 13068\n",
      "train_recall       0.629083\n",
      "test_recall        0.624494\n",
      "train_precision    0.820929\n",
      "test_precision     0.817072\n",
      "train_accuracy     0.913579\n",
      "test_accuracy      0.912355\n",
      "train_f1           0.712314\n",
      "test_f1            0.707908\n",
      "train_roc_auc      0.915751\n",
      "test_roc_auc       0.912105\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.626181</td>\n",
       "      <td>0.820152</td>\n",
       "      <td>0.817381</td>\n",
       "      <td>0.913571</td>\n",
       "      <td>0.912618</td>\n",
       "      <td>0.712559</td>\n",
       "      <td>0.709119</td>\n",
       "      <td>0.915276</td>\n",
       "      <td>0.912532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.628909</td>\n",
       "      <td>0.623482</td>\n",
       "      <td>0.822569</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.913819</td>\n",
       "      <td>0.912388</td>\n",
       "      <td>0.712820</td>\n",
       "      <td>0.707684</td>\n",
       "      <td>0.915209</td>\n",
       "      <td>0.915127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.628121</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>0.822628</td>\n",
       "      <td>0.821983</td>\n",
       "      <td>0.913724</td>\n",
       "      <td>0.912388</td>\n",
       "      <td>0.712336</td>\n",
       "      <td>0.706184</td>\n",
       "      <td>0.915520</td>\n",
       "      <td>0.912319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.626913</td>\n",
       "      <td>0.819473</td>\n",
       "      <td>0.814144</td>\n",
       "      <td>0.913400</td>\n",
       "      <td>0.912228</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>0.708365</td>\n",
       "      <td>0.917458</td>\n",
       "      <td>0.905123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.628951</td>\n",
       "      <td>0.626913</td>\n",
       "      <td>0.819821</td>\n",
       "      <td>0.813668</td>\n",
       "      <td>0.913381</td>\n",
       "      <td>0.912152</td>\n",
       "      <td>0.711813</td>\n",
       "      <td>0.708185</td>\n",
       "      <td>0.915294</td>\n",
       "      <td>0.915423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_recall  test_recall  train_precision  test_precision  train_accuracy  \\\n",
       "0      0.629921     0.626181         0.820152        0.817381        0.913571   \n",
       "1      0.628909     0.623482         0.822569        0.818182        0.913819   \n",
       "2      0.628121     0.618983         0.822628        0.821983        0.913724   \n",
       "3      0.629513     0.626913         0.819473        0.814144        0.913400   \n",
       "4      0.628951     0.626913         0.819821        0.813668        0.913381   \n",
       "\n",
       "   test_accuracy  train_f1   test_f1  train_roc_auc  test_roc_auc  \n",
       "0       0.912618  0.712559  0.709119       0.915276      0.912532  \n",
       "1       0.912388  0.712820  0.707684       0.915209      0.915127  \n",
       "2       0.912388  0.712336  0.706184       0.915520      0.912319  \n",
       "3       0.912228  0.712041  0.708365       0.917458      0.905123  \n",
       "4       0.912152  0.711813  0.708185       0.915294      0.915423  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='none', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='lbfgs',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                        )\n",
    "details, scores, perf = CV(dataClean, clf)\n",
    "clfs['logi_nr'] = details\n",
    "print (perf.mean())\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45740, 208) (45740,) (19603, 208) (19603,)\n",
      "train score = 0.91454\n",
      "0.829515890424935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " sex_F  -0.148778\n",
       " sex_M  -0.487780\n",
       " race_A -0.137379\n",
       " race_B -0.041836\n",
       " race_I -0.448264\n",
       " race_P  0.114376\n",
       " race_Q  0.060977\n",
       " race_W -0.273369\n",
       " race_Z  0.088938,                0\n",
       " sex_F   0.034700\n",
       " sex_M   0.027237\n",
       " race_A  0.013963\n",
       " race_B  0.026062\n",
       " race_I  0.014706\n",
       " race_P  0.025907\n",
       " race_Q  0.033601\n",
       " race_W  0.033368\n",
       " race_Z  0.012739,                0\n",
       " sex_F   0.675958\n",
       " sex_M   0.604255\n",
       " race_A  0.581818\n",
       " race_B  0.593310\n",
       " race_I  0.375000\n",
       " race_P  0.658088\n",
       " race_Q  0.649611\n",
       " race_W  0.557325\n",
       " race_Z  0.685714)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='none', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='lbfgs',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                        )\n",
    "X_train, X_test, y_train, y_test = splitData(dataClean)\n",
    "scaler, clf = trainModel(X_train, y_train, clf)\n",
    "X = fairness_on_test(X_test, y_test, scaler, clf)\n",
    "fair_coef = get_fair_coef(X_train, clf)\n",
    "fpr_df, tpr_df = FPR(X, X_train)\n",
    "fair_coef, fpr_df, tpr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without any reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19735 4935\n",
      "1 19735 4935\n",
      "2 19736 4934\n",
      "3 19737 4933\n",
      "4 19737 4933\n",
      "train_recall       0.787096\n",
      "test_recall        0.781876\n",
      "train_precision    0.877419\n",
      "test_precision     0.872130\n",
      "train_accuracy     0.854560\n",
      "test_accuracy      0.850101\n",
      "train_f1           0.829805\n",
      "test_f1            0.824510\n",
      "train_roc_auc      0.919815\n",
      "test_roc_auc       0.914600\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.786052</td>\n",
       "      <td>0.789024</td>\n",
       "      <td>0.876238</td>\n",
       "      <td>0.875686</td>\n",
       "      <td>0.853610</td>\n",
       "      <td>0.854509</td>\n",
       "      <td>0.828698</td>\n",
       "      <td>0.830099</td>\n",
       "      <td>0.919478</td>\n",
       "      <td>0.917437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.788751</td>\n",
       "      <td>0.780027</td>\n",
       "      <td>0.878147</td>\n",
       "      <td>0.865269</td>\n",
       "      <td>0.855536</td>\n",
       "      <td>0.846201</td>\n",
       "      <td>0.831052</td>\n",
       "      <td>0.820440</td>\n",
       "      <td>0.919855</td>\n",
       "      <td>0.913984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.784139</td>\n",
       "      <td>0.783626</td>\n",
       "      <td>0.877628</td>\n",
       "      <td>0.874937</td>\n",
       "      <td>0.853516</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.828254</td>\n",
       "      <td>0.826768</td>\n",
       "      <td>0.918777</td>\n",
       "      <td>0.917816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.785176</td>\n",
       "      <td>0.792529</td>\n",
       "      <td>0.877010</td>\n",
       "      <td>0.872646</td>\n",
       "      <td>0.853625</td>\n",
       "      <td>0.854450</td>\n",
       "      <td>0.828556</td>\n",
       "      <td>0.830660</td>\n",
       "      <td>0.920047</td>\n",
       "      <td>0.913472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.791362</td>\n",
       "      <td>0.764176</td>\n",
       "      <td>0.878073</td>\n",
       "      <td>0.872111</td>\n",
       "      <td>0.856513</td>\n",
       "      <td>0.843300</td>\n",
       "      <td>0.832466</td>\n",
       "      <td>0.814584</td>\n",
       "      <td>0.920915</td>\n",
       "      <td>0.910292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_recall  test_recall  train_precision  test_precision  train_accuracy  \\\n",
       "0      0.786052     0.789024         0.876238        0.875686        0.853610   \n",
       "1      0.788751     0.780027         0.878147        0.865269        0.855536   \n",
       "2      0.784139     0.783626         0.877628        0.874937        0.853516   \n",
       "3      0.785176     0.792529         0.877010        0.872646        0.853625   \n",
       "4      0.791362     0.764176         0.878073        0.872111        0.856513   \n",
       "\n",
       "   test_accuracy  train_f1   test_f1  train_roc_auc  test_roc_auc  \n",
       "0       0.854509  0.828698  0.830099       0.919478      0.917437  \n",
       "1       0.846201  0.831052  0.820440       0.919855      0.913984  \n",
       "2       0.852047  0.828254  0.826768       0.918777      0.917816  \n",
       "3       0.854450  0.828556  0.830660       0.920047      0.913472  \n",
       "4       0.843300  0.832466  0.814584       0.920915      0.910292  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='none', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='lbfgs',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                        )\n",
    "details, scores, perf = CV(data_used, clf)\n",
    "clfs['logi_nr'] = details\n",
    "print (perf.mean())\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17269, 208) (17269,) (7401, 208) (7401,)\n",
      "train score = 0.85431\n",
      "0.5549250101337657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " sex_F   0.140808\n",
       " sex_M  -0.094797\n",
       " race_A -0.086671\n",
       " race_B  0.014945\n",
       " race_I -0.005821\n",
       " race_P  0.187162\n",
       " race_Q  0.099414\n",
       " race_W -0.213482\n",
       " race_Z  0.050464,                0\n",
       " sex_F   0.129921\n",
       " sex_M   0.097067\n",
       " race_A  0.032110\n",
       " race_B  0.099453\n",
       " race_I  0.200000\n",
       " race_P  0.118774\n",
       " race_Q  0.112568\n",
       " race_W  0.085595\n",
       " race_Z  0.162162,                0\n",
       " sex_F   0.819113\n",
       " sex_M   0.795068\n",
       " race_A  0.726496\n",
       " race_B  0.787416\n",
       " race_I  0.857143\n",
       " race_P  0.832143\n",
       " race_Q  0.818907\n",
       " race_W  0.761468\n",
       " race_Z  0.937500)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='none', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='lbfgs',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                        )\n",
    "X_train, X_test, y_train, y_test = splitData(data_used)\n",
    "scaler, clf = trainModel(X_train, y_train, clf)\n",
    "X = fairness_on_test(X_test, y_test, scaler, clf)\n",
    "fair_coef = get_fair_coef(X_train, clf)\n",
    "fpr_df, tpr_df = FPR(X, X_train)\n",
    "fair_coef, fpr_df, tpr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with l1 reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19735 4935\n",
      "1 19735 4935\n",
      "2 19736 4934\n",
      "3 19737 4933\n",
      "4 19737 4933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.782340</td>\n",
       "      <td>0.787224</td>\n",
       "      <td>0.877160</td>\n",
       "      <td>0.876314</td>\n",
       "      <td>0.852597</td>\n",
       "      <td>0.854103</td>\n",
       "      <td>0.827041</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.918995</td>\n",
       "      <td>0.918014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.785939</td>\n",
       "      <td>0.778228</td>\n",
       "      <td>0.880418</td>\n",
       "      <td>0.868038</td>\n",
       "      <td>0.855485</td>\n",
       "      <td>0.846809</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>0.820683</td>\n",
       "      <td>0.919570</td>\n",
       "      <td>0.913654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.780652</td>\n",
       "      <td>0.778677</td>\n",
       "      <td>0.878481</td>\n",
       "      <td>0.876012</td>\n",
       "      <td>0.852554</td>\n",
       "      <td>0.850628</td>\n",
       "      <td>0.826683</td>\n",
       "      <td>0.824482</td>\n",
       "      <td>0.918308</td>\n",
       "      <td>0.918937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.781577</td>\n",
       "      <td>0.793429</td>\n",
       "      <td>0.876514</td>\n",
       "      <td>0.875372</td>\n",
       "      <td>0.852004</td>\n",
       "      <td>0.856071</td>\n",
       "      <td>0.826327</td>\n",
       "      <td>0.832389</td>\n",
       "      <td>0.919556</td>\n",
       "      <td>0.914758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.786638</td>\n",
       "      <td>0.761026</td>\n",
       "      <td>0.877101</td>\n",
       "      <td>0.875712</td>\n",
       "      <td>0.854233</td>\n",
       "      <td>0.843706</td>\n",
       "      <td>0.829410</td>\n",
       "      <td>0.814351</td>\n",
       "      <td>0.920460</td>\n",
       "      <td>0.910362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_recall  test_recall  train_precision  test_precision  train_accuracy  \\\n",
       "0      0.782340     0.787224         0.877160        0.876314        0.852597   \n",
       "1      0.785939     0.778228         0.880418        0.868038        0.855485   \n",
       "2      0.780652     0.778677         0.878481        0.876012        0.852554   \n",
       "3      0.781577     0.793429         0.876514        0.875372        0.852004   \n",
       "4      0.786638     0.761026         0.877101        0.875712        0.854233   \n",
       "\n",
       "   test_accuracy  train_f1   test_f1  train_roc_auc  test_roc_auc  \n",
       "0       0.854103  0.827041  0.829384       0.918995      0.918014  \n",
       "1       0.846809  0.830500  0.820683       0.919570      0.913654  \n",
       "2       0.850628  0.826683  0.824482       0.918308      0.918937  \n",
       "3       0.856071  0.826327  0.832389       0.919556      0.914758  \n",
       "4       0.843706  0.829410  0.814351       0.920460      0.910362  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='l1', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                        )\n",
    "details, scores, perf = CV(data_used, clf)\n",
    "clfs['logi_l2'] = clf\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_recall       0.783429\n",
       "test_recall        0.779717\n",
       "train_precision    0.877935\n",
       "test_precision     0.874290\n",
       "train_accuracy     0.853375\n",
       "test_accuracy      0.850263\n",
       "train_f1           0.827992\n",
       "test_f1            0.824258\n",
       "train_roc_auc      0.919378\n",
       "test_roc_auc       0.915145\n",
       "dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17269, 208) (17269,) (7401, 208) (7401,)\n",
      "train score = 0.85309\n",
      "0.5549250101337657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               0\n",
       " sex_F   0.001923\n",
       " sex_M  -0.232384\n",
       " race_A -0.106998\n",
       " race_B -0.026450\n",
       " race_I  0.000000\n",
       " race_P  0.141030\n",
       " race_Q  0.067481\n",
       " race_W -0.214459\n",
       " race_Z  0.000000,                0\n",
       " sex_F   0.137795\n",
       " sex_M   0.093174\n",
       " race_A  0.027523\n",
       " race_B  0.097172\n",
       " race_I  0.200000\n",
       " race_P  0.118774\n",
       " race_Q  0.109290\n",
       " race_W  0.077244\n",
       " race_Z  0.162162,                0\n",
       " sex_F   0.822526\n",
       " sex_M   0.791403\n",
       " race_A  0.709402\n",
       " race_B  0.782529\n",
       " race_I  0.857143\n",
       " race_P  0.832143\n",
       " race_Q  0.816629\n",
       " race_W  0.767584\n",
       " race_Z  0.937500)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True,\n",
    "                         penalty='l1', # no regularization, l1, l2, elasticnet\n",
    "                         random_state=0,\n",
    "                         solver='saga',\n",
    "                         multi_class='ovr',\n",
    "                         class_weight='none',\n",
    "                         max_iter=1000,\n",
    "                         \n",
    "                        )\n",
    "X_train, X_test, y_train, y_test = splitData(data_used)\n",
    "scaler, clf = trainModel(X_train, y_train, clf)\n",
    "X = fairness_on_test(X_test, y_test, scaler, clf)\n",
    "fair_coef = get_fair_coef(X_train, clf)\n",
    "fpr_df, tpr_df = FPR(X, X_train)\n",
    "fair_coef, fpr_df, tpr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sumissue</td>\n",
       "      <td>-3.144655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_121</td>\n",
       "      <td>-1.423483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_12</td>\n",
       "      <td>-1.168010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>typeofid_R</td>\n",
       "      <td>-1.101323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_52</td>\n",
       "      <td>-1.075967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_120</td>\n",
       "      <td>-0.786389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>radio</td>\n",
       "      <td>-0.717327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_67</td>\n",
       "      <td>-0.683681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_50</td>\n",
       "      <td>-0.680272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_cloth</td>\n",
       "      <td>-0.560391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_70</td>\n",
       "      <td>-0.556405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>explnstp</td>\n",
       "      <td>-0.522493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_78</td>\n",
       "      <td>-0.516991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_16</td>\n",
       "      <td>-0.514917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_21</td>\n",
       "      <td>-0.509837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_14</td>\n",
       "      <td>-0.507368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_84</td>\n",
       "      <td>-0.480763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_122</td>\n",
       "      <td>-0.479340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_10</td>\n",
       "      <td>-0.468055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_18</td>\n",
       "      <td>-0.402290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_casng</td>\n",
       "      <td>-0.384301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_30</td>\n",
       "      <td>-0.382137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_106</td>\n",
       "      <td>-0.373828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_33</td>\n",
       "      <td>-0.366594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_103</td>\n",
       "      <td>-0.352778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_bulge</td>\n",
       "      <td>-0.351169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_lkout</td>\n",
       "      <td>-0.341772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_13</td>\n",
       "      <td>-0.340379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_hdobj</td>\n",
       "      <td>-0.324703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_3</td>\n",
       "      <td>-0.296105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_113</td>\n",
       "      <td>-0.294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_ZZ</td>\n",
       "      <td>-0.287104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_108</td>\n",
       "      <td>-0.284339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_4</td>\n",
       "      <td>-0.277173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_BR</td>\n",
       "      <td>-0.256807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_63</td>\n",
       "      <td>-0.243399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_41</td>\n",
       "      <td>-0.243224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_101</td>\n",
       "      <td>-0.239032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_71</td>\n",
       "      <td>-0.239006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sex_M</td>\n",
       "      <td>-0.232384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_17</td>\n",
       "      <td>-0.228411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_38</td>\n",
       "      <td>-0.222758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_39</td>\n",
       "      <td>-0.219381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>othpers</td>\n",
       "      <td>-0.218114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_Z</td>\n",
       "      <td>-0.217141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_BR</td>\n",
       "      <td>-0.216969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_W</td>\n",
       "      <td>-0.214459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_45</td>\n",
       "      <td>-0.188796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_90</td>\n",
       "      <td>-0.183903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_GY</td>\n",
       "      <td>-0.177808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_othsw</td>\n",
       "      <td>-0.174062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_knowl</td>\n",
       "      <td>-0.162598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_BK</td>\n",
       "      <td>-0.148984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_GR</td>\n",
       "      <td>-0.145811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_69</td>\n",
       "      <td>-0.128146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_76</td>\n",
       "      <td>-0.123597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_28</td>\n",
       "      <td>-0.122047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_BK</td>\n",
       "      <td>-0.117868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_vcrim</td>\n",
       "      <td>-0.113167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>offunif</td>\n",
       "      <td>-0.111609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_7</td>\n",
       "      <td>-0.109155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_73</td>\n",
       "      <td>-0.109149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_5</td>\n",
       "      <td>-0.107880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_A</td>\n",
       "      <td>-0.106998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_102</td>\n",
       "      <td>-0.106390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_other</td>\n",
       "      <td>-0.105294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_100</td>\n",
       "      <td>-0.100766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_inves</td>\n",
       "      <td>-0.098608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_verbl</td>\n",
       "      <td>-0.087941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timestop</td>\n",
       "      <td>-0.079757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_furtv</td>\n",
       "      <td>-0.070745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_20</td>\n",
       "      <td>-0.069609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sp2</td>\n",
       "      <td>-0.065816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_75</td>\n",
       "      <td>-0.064103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_66</td>\n",
       "      <td>-0.063734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_13</td>\n",
       "      <td>-0.057979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_62</td>\n",
       "      <td>-0.055848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_28</td>\n",
       "      <td>-0.054581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_other</td>\n",
       "      <td>-0.052692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_incid</td>\n",
       "      <td>-0.052630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SP500</td>\n",
       "      <td>-0.045306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_C</td>\n",
       "      <td>-0.040998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>build_H</td>\n",
       "      <td>-0.040783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>year</td>\n",
       "      <td>-0.033002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_assoc</td>\n",
       "      <td>-0.030037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_F</td>\n",
       "      <td>-0.030018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_T</td>\n",
       "      <td>-0.029361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_B</td>\n",
       "      <td>-0.026450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_time</td>\n",
       "      <td>-0.015011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ht</td>\n",
       "      <td>-0.011096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>build_M</td>\n",
       "      <td>-0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_94</td>\n",
       "      <td>-0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_attir</td>\n",
       "      <td>-0.007176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_8</td>\n",
       "      <td>-0.006838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perobs</td>\n",
       "      <td>-0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_DF</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_46</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_DY</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_BL</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_88</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_43</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>riflshot</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asltweap</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timestop3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timestop2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_rfcmp</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_114</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_111</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_H</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_Z</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_22</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>build_U</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_79</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_107</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_24</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_49</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_31</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_I</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_33</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_34</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_36</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_23</td>\n",
       "      <td>0.001534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sex_F</td>\n",
       "      <td>0.001923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>weight</td>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_6</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>age</td>\n",
       "      <td>0.013157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_vcact</td>\n",
       "      <td>0.015179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_44</td>\n",
       "      <td>0.019049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_stsnd</td>\n",
       "      <td>0.020196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>perstop</td>\n",
       "      <td>0.027837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_other</td>\n",
       "      <td>0.028232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_18</td>\n",
       "      <td>0.042115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>month</td>\n",
       "      <td>0.043318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_109</td>\n",
       "      <td>0.045491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_Q</td>\n",
       "      <td>0.067481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>typeofid_V</td>\n",
       "      <td>0.074288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_112</td>\n",
       "      <td>0.080699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_BL</td>\n",
       "      <td>0.084877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>build_T</td>\n",
       "      <td>0.093349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_20</td>\n",
       "      <td>0.097118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_RA</td>\n",
       "      <td>0.110119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_drgtr</td>\n",
       "      <td>0.127115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_77</td>\n",
       "      <td>0.131258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_BA</td>\n",
       "      <td>0.131319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_83</td>\n",
       "      <td>0.139217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>race_P</td>\n",
       "      <td>0.141030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_cgdir</td>\n",
       "      <td>0.141651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rf_vcrim</td>\n",
       "      <td>0.153684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>frisked</td>\n",
       "      <td>0.157138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_105</td>\n",
       "      <td>0.163447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>typeofid_P</td>\n",
       "      <td>0.165470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_9</td>\n",
       "      <td>0.167383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_descr</td>\n",
       "      <td>0.174026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_M</td>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_60</td>\n",
       "      <td>0.186531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_22</td>\n",
       "      <td>0.189425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_GY</td>\n",
       "      <td>0.204847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_evasv</td>\n",
       "      <td>0.253328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>typeofid_O</td>\n",
       "      <td>0.268644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_48</td>\n",
       "      <td>0.286612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_10</td>\n",
       "      <td>0.291713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_proxm</td>\n",
       "      <td>0.301737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_24</td>\n",
       "      <td>0.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_49</td>\n",
       "      <td>0.329120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eyecolor_HA</td>\n",
       "      <td>0.337594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_115</td>\n",
       "      <td>0.362029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_61</td>\n",
       "      <td>0.362380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_72</td>\n",
       "      <td>0.364199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_81</td>\n",
       "      <td>0.366752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_32</td>\n",
       "      <td>0.374129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_17</td>\n",
       "      <td>0.387108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_32</td>\n",
       "      <td>0.408272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_68</td>\n",
       "      <td>0.421729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ac_rept</td>\n",
       "      <td>0.435519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_outln</td>\n",
       "      <td>0.464644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_53</td>\n",
       "      <td>0.470694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haircolr_SP</td>\n",
       "      <td>0.476554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_11</td>\n",
       "      <td>0.483313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_25</td>\n",
       "      <td>0.498582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_104</td>\n",
       "      <td>0.644338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cs_objcs</td>\n",
       "      <td>0.732796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_43</td>\n",
       "      <td>0.734407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_admis</td>\n",
       "      <td>0.887314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_26</td>\n",
       "      <td>0.895487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_47</td>\n",
       "      <td>0.911591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>inout</td>\n",
       "      <td>0.918087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_110</td>\n",
       "      <td>0.921391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_123</td>\n",
       "      <td>1.125079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_19</td>\n",
       "      <td>1.294258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>crimsusp_50</td>\n",
       "      <td>1.372930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>searched</td>\n",
       "      <td>1.439694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_40</td>\n",
       "      <td>1.541140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addrpct_42</td>\n",
       "      <td>1.731959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sb_other</td>\n",
       "      <td>1.880361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>othrweap</td>\n",
       "      <td>2.048827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>knifcuti</td>\n",
       "      <td>2.233324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pistol</td>\n",
       "      <td>2.985725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>contrabn</td>\n",
       "      <td>3.107645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "sumissue       -3.144655\n",
       "addrpct_121    -1.423483\n",
       "crimsusp_12    -1.168010\n",
       "typeofid_R     -1.101323\n",
       "addrpct_52     -1.075967\n",
       "addrpct_120    -0.786389\n",
       "radio          -0.717327\n",
       "addrpct_67     -0.683681\n",
       "addrpct_50     -0.680272\n",
       "cs_cloth       -0.560391\n",
       "addrpct_70     -0.556405\n",
       "explnstp       -0.522493\n",
       "addrpct_78     -0.516991\n",
       "crimsusp_16    -0.514917\n",
       "crimsusp_21    -0.509837\n",
       "addrpct_14     -0.507368\n",
       "addrpct_84     -0.480763\n",
       "addrpct_122    -0.479340\n",
       "addrpct_10     -0.468055\n",
       "addrpct_18     -0.402290\n",
       "cs_casng       -0.384301\n",
       "addrpct_30     -0.382137\n",
       "addrpct_106    -0.373828\n",
       "addrpct_33     -0.366594\n",
       "addrpct_103    -0.352778\n",
       "cs_bulge       -0.351169\n",
       "cs_lkout       -0.341772\n",
       "crimsusp_13    -0.340379\n",
       "sb_hdobj       -0.324703\n",
       "crimsusp_3     -0.296105\n",
       "addrpct_113    -0.294933\n",
       "haircolr_ZZ    -0.287104\n",
       "addrpct_108    -0.284339\n",
       "crimsusp_4     -0.277173\n",
       "eyecolor_BR    -0.256807\n",
       "addrpct_63     -0.243399\n",
       "addrpct_41     -0.243224\n",
       "addrpct_101    -0.239032\n",
       "addrpct_71     -0.239006\n",
       "sex_M          -0.232384\n",
       "addrpct_17     -0.228411\n",
       "crimsusp_38    -0.222758\n",
       "crimsusp_39    -0.219381\n",
       "othpers        -0.218114\n",
       "eyecolor_Z     -0.217141\n",
       "haircolr_BR    -0.216969\n",
       "race_W         -0.214459\n",
       "addrpct_45     -0.188796\n",
       "addrpct_90     -0.183903\n",
       "haircolr_GY    -0.177808\n",
       "rf_othsw       -0.174062\n",
       "rf_knowl       -0.162598\n",
       "haircolr_BK    -0.148984\n",
       "eyecolor_GR    -0.145811\n",
       "addrpct_69     -0.128146\n",
       "addrpct_76     -0.123597\n",
       "addrpct_28     -0.122047\n",
       "eyecolor_BK    -0.117868\n",
       "cs_vcrim       -0.113167\n",
       "offunif        -0.111609\n",
       "addrpct_7      -0.109155\n",
       "addrpct_73     -0.109149\n",
       "addrpct_5      -0.107880\n",
       "race_A         -0.106998\n",
       "addrpct_102    -0.106390\n",
       "ac_other       -0.105294\n",
       "addrpct_100    -0.100766\n",
       "ac_inves       -0.098608\n",
       "rf_verbl       -0.087941\n",
       "timestop       -0.079757\n",
       "cs_furtv       -0.070745\n",
       "crimsusp_20    -0.069609\n",
       "sp2            -0.065816\n",
       "addrpct_75     -0.064103\n",
       "addrpct_66     -0.063734\n",
       "addrpct_13     -0.057979\n",
       "addrpct_62     -0.055848\n",
       "crimsusp_28    -0.054581\n",
       "cs_other       -0.052692\n",
       "ac_incid       -0.052630\n",
       "SP500          -0.045306\n",
       "CPI_C          -0.040998\n",
       "build_H        -0.040783\n",
       "year           -0.033002\n",
       "ac_assoc       -0.030037\n",
       "CPI_F          -0.030018\n",
       "CPI_T          -0.029361\n",
       "race_B         -0.026450\n",
       "ac_time        -0.015011\n",
       "ht             -0.011096\n",
       "build_M        -0.010754\n",
       "addrpct_94     -0.008166\n",
       "rf_attir       -0.007176\n",
       "crimsusp_8     -0.006838\n",
       "perobs         -0.006096\n",
       "eyecolor_DF     0.000000\n",
       "addrpct_46      0.000000\n",
       "addrpct_34      0.000000\n",
       "haircolr_DY     0.000000\n",
       "haircolr_BL     0.000000\n",
       "addrpct_88      0.000000\n",
       "crimsusp_43     0.000000\n",
       "crimsusp_6      0.000000\n",
       "CPI2            0.000000\n",
       "CPI             0.000000\n",
       "riflshot        0.000000\n",
       "asltweap        0.000000\n",
       "timestop3       0.000000\n",
       "timestop2       0.000000\n",
       "rf_rfcmp        0.000000\n",
       "addrpct_114     0.000000\n",
       "addrpct_111     0.000000\n",
       "CPI_H           0.000000\n",
       "race_Z          0.000000\n",
       "addrpct_22      0.000000\n",
       "crimsusp_9      0.000000\n",
       "build_U         0.000000\n",
       "addrpct_79      0.000000\n",
       "addrpct_107     0.000000\n",
       "addrpct_1       0.000000\n",
       "crimsusp_23     0.000000\n",
       "crimsusp_24     0.000000\n",
       "crimsusp_29     0.000000\n",
       "crimsusp_49     0.000000\n",
       "crimsusp_31     0.000000\n",
       "race_I          0.000000\n",
       "crimsusp_33     0.000000\n",
       "crimsusp_34     0.000000\n",
       "crimsusp_14     0.000000\n",
       "crimsusp_37     0.000000\n",
       "crimsusp_36     0.000000\n",
       "addrpct_23      0.001534\n",
       "sex_F           0.001923\n",
       "weight          0.005776\n",
       "addrpct_6       0.006437\n",
       "age             0.013157\n",
       "rf_vcact        0.015179\n",
       "addrpct_44      0.019049\n",
       "ac_stsnd        0.020196\n",
       "perstop         0.027837\n",
       "crimsusp_other  0.028232\n",
       "crimsusp_18     0.042115\n",
       "month           0.043318\n",
       "addrpct_109     0.045491\n",
       "race_Q          0.067481\n",
       "typeofid_V      0.074288\n",
       "addrpct_112     0.080699\n",
       "eyecolor_BL     0.084877\n",
       "build_T         0.093349\n",
       "addrpct_20      0.097118\n",
       "haircolr_RA     0.110119\n",
       "cs_drgtr        0.127115\n",
       "addrpct_77      0.131258\n",
       "haircolr_BA     0.131319\n",
       "addrpct_83      0.139217\n",
       "race_P          0.141030\n",
       "ac_cgdir        0.141651\n",
       "rf_vcrim        0.153684\n",
       "frisked         0.157138\n",
       "addrpct_105     0.163447\n",
       "typeofid_P      0.165470\n",
       "addrpct_9       0.167383\n",
       "cs_descr        0.174026\n",
       "CPI_M           0.182574\n",
       "addrpct_60      0.186531\n",
       "crimsusp_22     0.189425\n",
       "eyecolor_GY     0.204847\n",
       "ac_evasv        0.253328\n",
       "typeofid_O      0.268644\n",
       "addrpct_48      0.286612\n",
       "crimsusp_10     0.291713\n",
       "ac_proxm        0.301737\n",
       "addrpct_24      0.305800\n",
       "addrpct_49      0.329120\n",
       "eyecolor_HA     0.337594\n",
       "addrpct_115     0.362029\n",
       "addrpct_61      0.362380\n",
       "addrpct_72      0.364199\n",
       "addrpct_81      0.366752\n",
       "crimsusp_32     0.374129\n",
       "crimsusp_17     0.387108\n",
       "addrpct_32      0.408272\n",
       "addrpct_68      0.421729\n",
       "ac_rept         0.435519\n",
       "sb_outln        0.464644\n",
       "crimsusp_53     0.470694\n",
       "haircolr_SP     0.476554\n",
       "crimsusp_11     0.483313\n",
       "addrpct_25      0.498582\n",
       "addrpct_104     0.644338\n",
       "cs_objcs        0.732796\n",
       "addrpct_43      0.734407\n",
       "sb_admis        0.887314\n",
       "addrpct_26      0.895487\n",
       "addrpct_47      0.911591\n",
       "inout           0.918087\n",
       "addrpct_110     0.921391\n",
       "addrpct_123     1.125079\n",
       "addrpct_19      1.294258\n",
       "crimsusp_50     1.372930\n",
       "searched        1.439694\n",
       "addrpct_40      1.541140\n",
       "addrpct_42      1.731959\n",
       "sb_other        1.880361\n",
       "othrweap        2.048827\n",
       "knifcuti        2.233324\n",
       "pistol          2.985725\n",
       "contrabn        3.107645"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_coef = pd.DataFrame(data=clf.coef_[0], index=X_train.columns)\n",
    "all_coef.sort_values(by=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CPI_F</td>\n",
       "      <td>-0.030018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_H</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_C</td>\n",
       "      <td>-0.040998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_T</td>\n",
       "      <td>-0.029361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI_M</td>\n",
       "      <td>0.182574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CPI2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SP500</td>\n",
       "      <td>-0.045306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sp2</td>\n",
       "      <td>-0.065816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "CPI_F -0.030018\n",
       "CPI_H  0.000000\n",
       "CPI_C -0.040998\n",
       "CPI_T -0.029361\n",
       "CPI_M  0.182574\n",
       "CPI    0.000000\n",
       "CPI2   0.000000\n",
       "SP500 -0.045306\n",
       "sp2   -0.065816"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iii = [i for i in all_coef.index if i.startswith('CPI') or i.startswith('SP') or i.startswith('sp')]\n",
    "all_coef.loc[iii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.8669637690341"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "93.5*np.exp(0.05*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172610976918178"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = (np.log(93.5/90)+(0.05+0.04/2)*0.5)/(0.2*np.sqrt(1/2))\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37583974145450827"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = (np.log(93.5/90)+(0.05+0.04/2)*0.5)/(0.2*np.sqrt(1/2)) - 0.2*np.sqrt(1/2)\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.427204131213074"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "93.5*0.6950-90*np.exp(-0.025)*0.6443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.705092082549939"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8.4272+90*np.exp(-0.025)-93.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10606601717798213"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.05/0.2-0.1)*np.sqrt(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5264722905128939"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5398*np.exp(-0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006045521371251361"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5 - 5.25*np.exp(-0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1111111111111107"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5.6*0.6 + 0*0.4)/1.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.810185185185183"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(19.185*0.6+3.11*0.4)/1.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5928.999999999999"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((100.8*0.6)**2+2*0.6*0.4*75.6**2+0.4**2*56.7**2)/1.08**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.25448513864539"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8.25+800-800*np.exp(-0.3))*0.1125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2518046738822477"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75.75*np.exp(.3)-100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
